{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义TextRNN结构，使用双向的LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRNN:\n",
    "    def __init__(self, batch_size, num_classes, vocab_size, sentence_len, embed_size, \n",
    "                 learning_rate, decay_steps, decay_rate, is_training):\n",
    "        #1.定义超参数\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sentence_len = sentence_len\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = embed_size #lstm层的维度\n",
    "        self.learning_rate = learning_rate\n",
    "        self.is_training = is_training\n",
    "        self.initializer = tf.random_normal_initializer(stddev=0.1)\n",
    "        \n",
    "        #epoch信息\n",
    "        self.global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        self.epoch_step = tf.Variable(0, trainable=False, name='epoch_step')\n",
    "        self.epoch_increment = tf.assign(self.epoch_step, tf.add(self.epoch_step, tf.constant(1)))\n",
    "        self.decay_steps, self.decay_rate = decay_steps, decay_rate\n",
    "        \n",
    "        #2.输入\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sentence_len], 'input_x')\n",
    "        self.input_y = tf.placeholder(tf.int32, [None], 'input_y') #单个标签\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name='dropout_keep_prob')\n",
    "        \n",
    "        #3.初始化全连接层参数\n",
    "        self.init_weight()\n",
    "        \n",
    "        #4.网络结构\n",
    "        self.logits = self.inference() #[batch_size, num_classes]\n",
    "        \n",
    "        #5.损失函数\n",
    "        self.loss_val = self.loss()\n",
    "        \n",
    "        #6.优化器\n",
    "        self.train_op = self.train()\n",
    "        \n",
    "        #7.计算acc\n",
    "        self.prediction = tf.argmax(self.logits, axis=1) #[batch_size]\n",
    "        is_right = tf.equal(tf.cast(self.prediction, tf.int32), self.input_y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(is_right, tf.float32))\n",
    "        \n",
    "    def init_weight(self):\n",
    "        self.Embedding = tf.get_variable('Embedding', [self.vocab_size, self.embed_size], dtype=tf.float32)\n",
    "        self.W = tf.get_variable('W', [self.hidden_size * 2, self.num_classes], dtype=tf.float32) #双向LSTM，输出concat，所以此处为2倍\n",
    "        self.b = tf.get_variable('b', [self.num_classes], dtype=tf.float32)\n",
    "        \n",
    "    def inference(self):\n",
    "        # a.embedding\n",
    "        self.sentence_embed = tf.nn.embedding_lookup(self.Embedding, self.input_x) #[batch_size, sentence_len, embed_size]\n",
    "        \n",
    "        # b.bidiretional lstm\n",
    "        self.fw_cell = tf.contrib.rnn.BasicLSTMCell(self.hidden_size) #前向单元\n",
    "        self.bw_cell = tf.contrib.rnn.BasicLSTMCell(self.hidden_size) #后向单元\n",
    "#         if self.dropout_keep_prob is not None:\n",
    "#             self.fw_cell = tf.contrib.rnn.DropoutWrapper(self.fw_cell, output_keep_prob=) \n",
    "                #input_keep_prob是对输入而言，output_keep_prb是对lstm各层而言\n",
    "        outputs, _ = tf.nn.bidirectional_dynamic_rnn(self.fw_cell, self.bw_cell, self.sentence_embed, dtype=tf.float32)\n",
    "        #输入为 [batch_size, sentence_len, embed_size]，输出为大小为2的元组，每个元素为[batch_size, sentence_len, hidden_size]\n",
    "        \n",
    "        # c.concat\n",
    "        fw_output = outputs[0][:,-1,:]\n",
    "        bw_output = outputs[1][:,-1,:] #[batch_size, 1, hidden_size]\n",
    "        final_output = tf.concat([fw_output, bw_output], axis=1) #[batch_size, 1, hidden_size*2]\n",
    "        final_output = tf.reshape(final_output, [-1, self.hidden_size*2]) #[batch_size, hidden_size * 2]\n",
    "        \n",
    "        # d.full_connection\n",
    "        logits = tf.matmul(final_output, self.W) + self.b #[batch_size, num_classes]\n",
    "        return logits\n",
    "    \n",
    "    def loss(self, l2_lambda=0.0001):\n",
    "        loss1 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.input_y, logits=self.logits)\n",
    "        #先将label转化为one-hot形式，再对logits计算softmax，最后计算交叉熵\n",
    "        loss1 = tf.reduce_mean(loss1)\n",
    "        loss2 = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()]) * l2_lambda\n",
    "        return loss1 + loss2\n",
    "    \n",
    "    def train(self):\n",
    "        learning_rate = tf.train.exponential_decay(self.learning_rate, self.global_step, self.decay_steps, self.decay_rate, staircase=True)\n",
    "        train_op = tf.contrib.layers.optimize_loss(self.loss_val, self.global_step, learning_rate, optimizer='Adam')\n",
    "        return train_op\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    num_classes=19\n",
    "    learning_rate=0.01\n",
    "    batch_size=15\n",
    "    decay_step=1000\n",
    "    decay_rate=0.9\n",
    "    sequence_length=5\n",
    "    vocab_size=10000\n",
    "    embed_size=100\n",
    "    is_training=True\n",
    "    dropout_keep_prob=0.5\n",
    "    \n",
    "    model = TextRNN(batch_size, num_classes, vocab_size, sequence_length, embed_size, \n",
    "                     learning_rate, decay_step, decay_rate, True)\n",
    "    print(tf.trainable_variables())\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        input_x = np.random.randint(0,100,size=(batch_size, sequence_length),dtype=np.int32)\n",
    "        input_y = np.random.randint(0, 19,size=(batch_size), dtype=np.int32)\n",
    "        for i in range(20):\n",
    "            #input_x = np.zeros((batch_size, sequence_length), dtype=np.int32)\n",
    "            #input_y = np.array([1,0,1,1,1,2,1,1], dtype=np.int32)\n",
    "            loss, acc, predict, _ = sess.run([model.loss_val, model.accuracy, model.prediction, model.train_op],\n",
    "                                            feed_dict={model.input_x: input_x, model.input_y: input_y,\n",
    "                                                       model.dropout_keep_prob: dropout_keep_prob})\n",
    "            print('loss:',loss, 'acc:', acc, 'label:', input_y, 'predict:', predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Embedding:0' shape=(10000, 100) dtype=float32_ref>, <tf.Variable 'W:0' shape=(200, 19) dtype=float32_ref>, <tf.Variable 'b:0' shape=(19,) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/fw/basic_lstm_cell/kernel:0' shape=(200, 400) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/fw/basic_lstm_cell/bias:0' shape=(400,) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/bw/basic_lstm_cell/kernel:0' shape=(200, 400) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/bw/basic_lstm_cell/bias:0' shape=(400,) dtype=float32_ref>]\n",
      "loss: 2.9575605 acc: 0.13333334 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13]\n",
      "loss: 2.8738065 acc: 0.13333334 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13]\n",
      "loss: 2.754186 acc: 0.13333334 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13]\n",
      "loss: 2.5552852 acc: 0.4 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11 13  5  9 13 13 13 11 13 13 13 13 13 13 11]\n",
      "loss: 2.2263947 acc: 0.6 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11 11  5 11 13 16 17 11 13 11 11 16  2 13 11]\n",
      "loss: 1.7614074 acc: 0.6 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11 11 11 11 13 16 17 11  7 14 11 16  2 13 11]\n",
      "loss: 1.3647178 acc: 0.4 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11 16 11 11 13 16 11 11 16 16 11 16 16 13 11]\n",
      "loss: 0.85778 acc: 0.93333334 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13 11]\n",
      "loss: 0.4564727 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.24476096 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.13127024 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.081464104 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.06269319 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.055726457 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.05473762 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.056272846 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.05851853 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.060859174 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.06308951 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n",
      "loss: 0.065122545 acc: 1.0 label: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0] predict: [11  7  5  9 13 16 17 11 18 14  1 16  2 13  0]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# from tflearn.data_utils import to_categorical, pad_sequences\n",
    "import os\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#定义超参数\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('batch_size', 512, 'batch_size')\n",
    "tf.app.flags.DEFINE_integer('num_classes', 1999, 'num_classes')\n",
    "tf.app.flags.DEFINE_integer('sentence_len', 100, 'length of each sentence')\n",
    "tf.app.flags.DEFINE_integer('embed_size', 100, 'embedding size')\n",
    "tf.app.flags.DEFINE_float('learning_rate', 0.01, '')\n",
    "tf.app.flags.DEFINE_float('decay_rate', 0.8, '')\n",
    "tf.app.flags.DEFINE_integer('decay_steps', 3000, 'number of steps before decay learning rate')\n",
    "tf.app.flags.DEFINE_bool('is_training', True, '')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_epoch', 20, 'number of epoch')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\"ckpt_dir\",\"testrnn_singlelabel_checkpoint/\",\"checkpoint location for the model\")\n",
    "tf.app.flags.DEFINE_string(\"cache_path\",\"textrnn_singlelabel_checkpoint/data_cache.pik\",\"data chche for the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def log(str):\n",
    "    t = time.localtime()\n",
    "    print(\"[%4d/%02d/%02d %02d:%02d:%02d]\"%(t.tm_year, t.tm_mon, t.tm_mday, t.tm_hour, t.tm_min, t.tm_sec), end=' ')\n",
    "    print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    #1.加载数据\n",
    "    base_path = '../zhihu_data/'\n",
    "    cache_file_h5py = base_path + 'data.h5'\n",
    "    cache_file_pickle = base_path + 'vocab_label.pik'\n",
    "    word2index,label2index,train_X,train_y,vaild_X,valid_y,test_X,test_y,embedding_final = load_data(cache_file_h5py, cache_file_pickle)\n",
    "    vocab_size = len(word2index)\n",
    "    \n",
    "    print(\"train_X.shape:\", np.array(train_X).shape)\n",
    "    print(\"train_y.shape:\", np.array(train_y).shape)\n",
    "    print(\"test_X.shape:\", np.array(test_X).shape)  # 每个list代表一句话\n",
    "    print(\"test_y.shape:\", np.array(test_y).shape)  \n",
    "    print(\"test_X[0]:\", test_X[0])  \n",
    "    print(\"test_y[0]:\", test_y[0]) \n",
    "    \n",
    "    #2.创建session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        model = TextRNN(FLAGS.batch_size, FLAGS.num_classes, vocab_size, FLAGS.sentence_len,FLAGS.embed_size, \n",
    "                        FLAGS.learning_rate, FLAGS.decay_steps, FLAGS.decay_rate, FLAGS.is_training)\n",
    "        saver = tf.train.Saver()\n",
    "        batch_size = FLAGS.batch_size\n",
    "        CONTINUE_TRAIN = False\n",
    "        if os.path.exists(FLAGS.ckpt_dir + 'checkpoint'):\n",
    "            log(\"restore from checkpoint\")\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(FLAGS.ckpt_dir))\n",
    "            if CONTINUE_TRAIN: log(\"continue training...\")\n",
    "        else:\n",
    "            log('init variables')\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "#             #是否使用embedding\n",
    "            print('assign pre-trained embedding')\n",
    "            embedding_assign = tf.assign(model.Embedding, tf.constant(np.array(embedding_final))) #为model.Embedding赋值\n",
    "            sess.run(embedding_assign)\n",
    "        if not os.path.exists(FLAGS.ckpt_dir + 'checkpoint') or CONTINUE_TRAIN:\n",
    "            num_of_data = len(train_y)\n",
    "            for _ in range(FLAGS.num_epoch):\n",
    "                epoch = sess.run(model.epoch_step)\n",
    "                loss, acc, counter = 0., 0., 0.\n",
    "                for start, end in zip(range(0, num_of_data, batch_size), range(batch_size, num_of_data, batch_size)):\n",
    "                    loss_tmp, acc_tmp, _ = sess.run([model.loss_val, model.accuracy, model.train_op], \n",
    "                                                    feed_dict={model.input_x: train_X[start:end,:100], model.input_y: train_y[start:end],\n",
    "                                                               model.dropout_keep_prob: 1})\n",
    "                    loss, acc, counter = loss + loss_tmp, acc + acc_tmp, counter + 1\n",
    "                    if counter % 200 == 0:\n",
    "                        log(\"Epoch %d\\Batch %d\\ Train Loss:%.3f\\ Train Accuracy:%.3f\"%(epoch, counter, loss/float(counter), acc/float(counter)))\n",
    "\n",
    "                print('run model on validation data...')\n",
    "                loss_valid, acc_valid = do_eval(sess, model, vaild_X, valid_y, batch_size)\n",
    "                log(\"Epoch %d\\ Validation Loss:%.3f/ Validation Accuracy:%.3f\"%(epoch, loss_valid, acc_valid))\n",
    "                #save the checkpoint\n",
    "                save_path = FLAGS.ckpt_dir + 'model.ckpt'\n",
    "                saver.save(sess, save_path, global_step=model.epoch_step)\n",
    "                sess.run(model.epoch_increment)\n",
    "            loss_valid, acc_valid = do_eval(sess, model, vaild_X, valid_y, batch_size)\n",
    "            log(\"Validation Loss:%.3f\\ Validation Accuracy:%.3f\"%(loss_valid, acc_valid))\n",
    "        loss_valid, acc_valid = do_eval(sess, model, vaild_X, valid_y, batch_size)\n",
    "        log(\"Validation Loss:%.3f\\ Validation Accuracy:%.3f\"%(loss_valid, acc_valid))    \n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(h5_file_path, pik_file_path):\n",
    "    if not os.path.exists(h5_file_path) or not os.path.exists(pik_file_path):\n",
    "        raise RuntimeError('No such file!!')\n",
    "\n",
    "    print('cache files exist, going to load in...')\n",
    "    print('loading h5_file...')\n",
    "    h5_file = h5py.File(h5_file_path, 'r')\n",
    "    print('h5_file.keys:', h5_file.keys())\n",
    "    train_X, train_y = h5_file['train_X'], h5_file['train_Y']\n",
    "    vaild_X, valid_y = h5_file['vaild_X'], h5_file['valid_Y']\n",
    "    test_X,  test_y  = h5_file['test_X'],  h5_file['test_Y']\n",
    "    embedding_final = h5_file['embedding']\n",
    "\n",
    "    print('loading pickle file')\n",
    "    word2index, label2index = None, None\n",
    "    with open(pik_file_path, 'rb') as pkl:\n",
    "        word2index,label2index = pickle.load(pkl)\n",
    "    print('cache files load successful!')\n",
    "    return word2index,label2index,train_X,train_y,vaild_X,valid_y,test_X,test_y, embedding_final\n",
    "\n",
    "def do_eval(sess, model, test_X, test_y, batch_size):\n",
    "#     test_X, test_y = test_X[:5000], test_y[:5000]\n",
    "    num_of_data = len(test_y)\n",
    "    loss, acc, counter = 0.0, 0.0, 0\n",
    "    for start, end in zip(range(0, num_of_data, batch_size), range(batch_size, num_of_data, batch_size)):\n",
    "        l,a = sess.run([model.loss_val, model.accuracy], \n",
    "                        feed_dict={model.input_x: test_X[start:end,:100], model.input_y: test_y[start:end], model.dropout_keep_prob:1.0})\n",
    "        loss, acc, counter = loss+l, acc+a, counter+1\n",
    "    return loss/float(counter), acc/float(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache files exist, going to load in...\n",
      "loading h5_file...\n",
      "h5_file.keys: KeysView(<HDF5 file \"data.h5\" (mode r)>)\n",
      "loading pickle file\n",
      "cache files load successful!\n",
      "train_X.shape: (2959966, 200)\n",
      "train_y.shape: (2959966,)\n",
      "test_X.shape: (20000, 200)\n",
      "test_y.shape: (20000,)\n",
      "test_X[0]: [ 579  343 1173 1843    5  583  292 1173 1843    5 1180 1299  989   10\n",
      "    2   68  153  168  531  109  260  217  277   81   59   81  116  514\n",
      "    6  221  253  224  154  718  553    4  806  538  732  264   74    6\n",
      "  221  224  154  326   11  167  136    4  257  145   37   74  175  214\n",
      "   11   57  110  221    6  364   89   20 4050 2344    4  257   78    9\n",
      "  991  326  221   89  699  133   11  597  679 1957  824  884  871 1957\n",
      "  824    4  178   87   87   78  196   52  552   69   47   20   12   37\n",
      " 1371   89    6  755  779   81  667  597    4  586  878    6   35   93\n",
      "    7  719  285  937   35  162   13   11    7 1371   89   35    4  201\n",
      "   68   81   97 1533   81  667  597    9  991  326   35  343  704   16\n",
      "    5   99   13    9  991  654  583  292    4   13  221    6  795  230\n",
      "   11   11  350   12  495  235    7  990  625  718  553  297  215  954\n",
      "  549    4   12  165  198   67   93    9  166  110  146    4   81   86\n",
      "   93  141   87 1146  118  224  154   93  147    9   20    4   81  407\n",
      "   92  116  514   12]\n",
      "test_y[0]: 808\n",
      "[2019/03/22 08:12:22] init variables\n",
      "assign pre-trained embedding\n",
      "[2019/03/22 08:13:50] Epoch 0\\Batch 200\\ Train Loss:7.673\\ Train Accuracy:0.007\n",
      "[2019/03/22 08:15:21] Epoch 0\\Batch 400\\ Train Loss:7.582\\ Train Accuracy:0.008\n",
      "[2019/03/22 08:17:01] Epoch 0\\Batch 600\\ Train Loss:7.447\\ Train Accuracy:0.010\n",
      "[2019/03/22 08:18:51] Epoch 0\\Batch 800\\ Train Loss:7.269\\ Train Accuracy:0.014\n",
      "[2019/03/22 08:20:41] Epoch 0\\Batch 1000\\ Train Loss:7.077\\ Train Accuracy:0.022\n",
      "[2019/03/22 08:22:30] Epoch 0\\Batch 1200\\ Train Loss:6.898\\ Train Accuracy:0.033\n",
      "[2019/03/22 08:24:20] Epoch 0\\Batch 1400\\ Train Loss:6.744\\ Train Accuracy:0.044\n",
      "[2019/03/22 08:26:10] Epoch 0\\Batch 1600\\ Train Loss:6.618\\ Train Accuracy:0.054\n",
      "[2019/03/22 08:28:01] Epoch 0\\Batch 1800\\ Train Loss:6.512\\ Train Accuracy:0.063\n",
      "[2019/03/22 08:29:50] Epoch 0\\Batch 2000\\ Train Loss:6.417\\ Train Accuracy:0.071\n",
      "[2019/03/22 08:31:41] Epoch 0\\Batch 2200\\ Train Loss:6.334\\ Train Accuracy:0.079\n",
      "[2019/03/22 08:33:30] Epoch 0\\Batch 2400\\ Train Loss:6.262\\ Train Accuracy:0.085\n",
      "[2019/03/22 08:35:21] Epoch 0\\Batch 2600\\ Train Loss:6.197\\ Train Accuracy:0.092\n",
      "[2019/03/22 08:37:11] Epoch 0\\Batch 2800\\ Train Loss:6.141\\ Train Accuracy:0.097\n",
      "[2019/03/22 08:39:01] Epoch 0\\Batch 3000\\ Train Loss:6.091\\ Train Accuracy:0.102\n",
      "[2019/03/22 08:40:51] Epoch 0\\Batch 3200\\ Train Loss:6.040\\ Train Accuracy:0.107\n",
      "[2019/03/22 08:42:39] Epoch 0\\Batch 3400\\ Train Loss:5.993\\ Train Accuracy:0.112\n",
      "[2019/03/22 08:44:29] Epoch 0\\Batch 3600\\ Train Loss:5.949\\ Train Accuracy:0.116\n",
      "[2019/03/22 08:46:18] Epoch 0\\Batch 3800\\ Train Loss:5.910\\ Train Accuracy:0.120\n",
      "[2019/03/22 08:48:07] Epoch 0\\Batch 4000\\ Train Loss:5.874\\ Train Accuracy:0.123\n",
      "[2019/03/22 08:49:58] Epoch 0\\Batch 4200\\ Train Loss:5.841\\ Train Accuracy:0.126\n",
      "[2019/03/22 08:51:47] Epoch 0\\Batch 4400\\ Train Loss:5.811\\ Train Accuracy:0.129\n",
      "[2019/03/22 08:53:36] Epoch 0\\Batch 4600\\ Train Loss:5.781\\ Train Accuracy:0.132\n",
      "[2019/03/22 08:55:26] Epoch 0\\Batch 4800\\ Train Loss:5.754\\ Train Accuracy:0.135\n",
      "[2019/03/22 08:57:16] Epoch 0\\Batch 5000\\ Train Loss:5.730\\ Train Accuracy:0.137\n",
      "[2019/03/22 08:59:04] Epoch 0\\Batch 5200\\ Train Loss:5.707\\ Train Accuracy:0.140\n",
      "[2019/03/22 09:00:54] Epoch 0\\Batch 5400\\ Train Loss:5.686\\ Train Accuracy:0.142\n",
      "[2019/03/22 09:02:42] Epoch 0\\Batch 5600\\ Train Loss:5.665\\ Train Accuracy:0.144\n",
      "run model on validation data...\n",
      "[2019/03/22 09:04:22] Epoch 0\\ Validation Loss:5.140/ Validation Accuracy:0.192\n",
      "[2019/03/22 09:06:12] Epoch 1\\Batch 200\\ Train Loss:5.095\\ Train Accuracy:0.202\n",
      "[2019/03/22 09:08:01] Epoch 1\\Batch 400\\ Train Loss:5.056\\ Train Accuracy:0.205\n",
      "[2019/03/22 09:09:50] Epoch 1\\Batch 600\\ Train Loss:5.029\\ Train Accuracy:0.207\n",
      "[2019/03/22 09:11:39] Epoch 1\\Batch 800\\ Train Loss:5.015\\ Train Accuracy:0.208\n",
      "[2019/03/22 09:13:29] Epoch 1\\Batch 1000\\ Train Loss:5.004\\ Train Accuracy:0.209\n",
      "[2019/03/22 09:15:19] Epoch 1\\Batch 1200\\ Train Loss:4.996\\ Train Accuracy:0.210\n",
      "[2019/03/22 09:17:08] Epoch 1\\Batch 1400\\ Train Loss:4.991\\ Train Accuracy:0.210\n",
      "[2019/03/22 09:18:57] Epoch 1\\Batch 1600\\ Train Loss:4.985\\ Train Accuracy:0.211\n",
      "[2019/03/22 09:20:47] Epoch 1\\Batch 1800\\ Train Loss:4.980\\ Train Accuracy:0.211\n",
      "[2019/03/22 09:22:37] Epoch 1\\Batch 2000\\ Train Loss:4.975\\ Train Accuracy:0.212\n",
      "[2019/03/22 09:24:28] Epoch 1\\Batch 2200\\ Train Loss:4.969\\ Train Accuracy:0.213\n",
      "[2019/03/22 09:26:19] Epoch 1\\Batch 2400\\ Train Loss:4.966\\ Train Accuracy:0.213\n",
      "[2019/03/22 09:28:09] Epoch 1\\Batch 2600\\ Train Loss:4.961\\ Train Accuracy:0.213\n",
      "[2019/03/22 09:29:57] Epoch 1\\Batch 2800\\ Train Loss:4.958\\ Train Accuracy:0.214\n",
      "[2019/03/22 09:31:48] Epoch 1\\Batch 3000\\ Train Loss:4.955\\ Train Accuracy:0.214\n",
      "[2019/03/22 09:33:36] Epoch 1\\Batch 3200\\ Train Loss:4.952\\ Train Accuracy:0.214\n",
      "[2019/03/22 09:35:26] Epoch 1\\Batch 3400\\ Train Loss:4.946\\ Train Accuracy:0.215\n",
      "[2019/03/22 09:37:16] Epoch 1\\Batch 3600\\ Train Loss:4.939\\ Train Accuracy:0.215\n",
      "[2019/03/22 09:39:06] Epoch 1\\Batch 3800\\ Train Loss:4.932\\ Train Accuracy:0.216\n",
      "[2019/03/22 09:40:56] Epoch 1\\Batch 4000\\ Train Loss:4.926\\ Train Accuracy:0.217\n",
      "[2019/03/22 09:42:45] Epoch 1\\Batch 4200\\ Train Loss:4.921\\ Train Accuracy:0.217\n",
      "[2019/03/22 09:44:35] Epoch 1\\Batch 4400\\ Train Loss:4.915\\ Train Accuracy:0.217\n",
      "[2019/03/22 09:46:24] Epoch 1\\Batch 4600\\ Train Loss:4.909\\ Train Accuracy:0.218\n",
      "[2019/03/22 09:48:14] Epoch 1\\Batch 4800\\ Train Loss:4.904\\ Train Accuracy:0.219\n",
      "[2019/03/22 09:50:04] Epoch 1\\Batch 5000\\ Train Loss:4.901\\ Train Accuracy:0.219\n",
      "[2019/03/22 09:51:53] Epoch 1\\Batch 5200\\ Train Loss:4.896\\ Train Accuracy:0.219\n",
      "[2019/03/22 09:53:42] Epoch 1\\Batch 5400\\ Train Loss:4.892\\ Train Accuracy:0.220\n",
      "[2019/03/22 09:55:33] Epoch 1\\Batch 5600\\ Train Loss:4.888\\ Train Accuracy:0.220\n",
      "run model on validation data...\n",
      "[2019/03/22 09:57:13] Epoch 1\\ Validation Loss:4.834/ Validation Accuracy:0.216\n",
      "[2019/03/22 09:59:01] Epoch 2\\Batch 200\\ Train Loss:4.783\\ Train Accuracy:0.230\n",
      "[2019/03/22 10:00:51] Epoch 2\\Batch 400\\ Train Loss:4.780\\ Train Accuracy:0.231\n",
      "[2019/03/22 10:02:40] Epoch 2\\Batch 600\\ Train Loss:4.766\\ Train Accuracy:0.232\n",
      "[2019/03/22 10:04:30] Epoch 2\\Batch 800\\ Train Loss:4.751\\ Train Accuracy:0.233\n",
      "[2019/03/22 10:06:20] Epoch 2\\Batch 1000\\ Train Loss:4.740\\ Train Accuracy:0.234\n",
      "[2019/03/22 10:08:09] Epoch 2\\Batch 1200\\ Train Loss:4.733\\ Train Accuracy:0.235\n",
      "[2019/03/22 10:10:00] Epoch 2\\Batch 1400\\ Train Loss:4.728\\ Train Accuracy:0.235\n",
      "[2019/03/22 10:11:51] Epoch 2\\Batch 1600\\ Train Loss:4.723\\ Train Accuracy:0.236\n",
      "[2019/03/22 10:13:46] Epoch 2\\Batch 1800\\ Train Loss:4.721\\ Train Accuracy:0.236\n",
      "[2019/03/22 10:15:40] Epoch 2\\Batch 2000\\ Train Loss:4.717\\ Train Accuracy:0.236\n",
      "[2019/03/22 10:17:33] Epoch 2\\Batch 2200\\ Train Loss:4.713\\ Train Accuracy:0.237\n",
      "[2019/03/22 10:19:29] Epoch 2\\Batch 2400\\ Train Loss:4.710\\ Train Accuracy:0.237\n",
      "[2019/03/22 10:21:24] Epoch 2\\Batch 2600\\ Train Loss:4.707\\ Train Accuracy:0.237\n",
      "[2019/03/22 10:23:18] Epoch 2\\Batch 2800\\ Train Loss:4.705\\ Train Accuracy:0.237\n",
      "[2019/03/22 10:25:13] Epoch 2\\Batch 3000\\ Train Loss:4.703\\ Train Accuracy:0.237\n",
      "[2019/03/22 10:27:03] Epoch 2\\Batch 3200\\ Train Loss:4.701\\ Train Accuracy:0.237\n",
      "[2019/03/22 10:28:52] Epoch 2\\Batch 3400\\ Train Loss:4.700\\ Train Accuracy:0.237\n",
      "[2019/03/22 10:30:40] Epoch 2\\Batch 3600\\ Train Loss:4.696\\ Train Accuracy:0.238\n",
      "[2019/03/22 10:32:32] Epoch 2\\Batch 3800\\ Train Loss:4.692\\ Train Accuracy:0.238\n",
      "[2019/03/22 10:34:21] Epoch 2\\Batch 4000\\ Train Loss:4.688\\ Train Accuracy:0.239\n",
      "[2019/03/22 10:36:12] Epoch 2\\Batch 4200\\ Train Loss:4.684\\ Train Accuracy:0.239\n",
      "[2019/03/22 10:38:07] Epoch 2\\Batch 4400\\ Train Loss:4.680\\ Train Accuracy:0.239\n",
      "[2019/03/22 10:40:01] Epoch 2\\Batch 4600\\ Train Loss:4.676\\ Train Accuracy:0.240\n",
      "[2019/03/22 10:41:55] Epoch 2\\Batch 4800\\ Train Loss:4.672\\ Train Accuracy:0.240\n",
      "[2019/03/22 10:43:51] Epoch 2\\Batch 5000\\ Train Loss:4.669\\ Train Accuracy:0.240\n",
      "[2019/03/22 10:45:46] Epoch 2\\Batch 5200\\ Train Loss:4.666\\ Train Accuracy:0.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/22 10:47:40] Epoch 2\\Batch 5400\\ Train Loss:4.663\\ Train Accuracy:0.241\n",
      "[2019/03/22 10:49:34] Epoch 2\\Batch 5600\\ Train Loss:4.661\\ Train Accuracy:0.241\n",
      "run model on validation data...\n",
      "[2019/03/22 10:51:20] Epoch 2\\ Validation Loss:4.646/ Validation Accuracy:0.234\n",
      "[2019/03/22 10:53:12] Epoch 3\\Batch 200\\ Train Loss:4.589\\ Train Accuracy:0.248\n",
      "[2019/03/22 10:55:07] Epoch 3\\Batch 400\\ Train Loss:4.585\\ Train Accuracy:0.249\n",
      "[2019/03/22 10:57:02] Epoch 3\\Batch 600\\ Train Loss:4.584\\ Train Accuracy:0.249\n",
      "[2019/03/22 10:58:57] Epoch 3\\Batch 800\\ Train Loss:4.578\\ Train Accuracy:0.249\n",
      "[2019/03/22 11:00:51] Epoch 3\\Batch 1000\\ Train Loss:4.570\\ Train Accuracy:0.250\n",
      "[2019/03/22 11:02:46] Epoch 3\\Batch 1200\\ Train Loss:4.563\\ Train Accuracy:0.251\n",
      "[2019/03/22 11:04:41] Epoch 3\\Batch 1400\\ Train Loss:4.558\\ Train Accuracy:0.251\n",
      "[2019/03/22 11:06:37] Epoch 3\\Batch 1600\\ Train Loss:4.553\\ Train Accuracy:0.252\n",
      "[2019/03/22 11:08:28] Epoch 3\\Batch 1800\\ Train Loss:4.549\\ Train Accuracy:0.252\n",
      "[2019/03/22 11:10:18] Epoch 3\\Batch 2000\\ Train Loss:4.546\\ Train Accuracy:0.252\n",
      "[2019/03/22 11:12:07] Epoch 3\\Batch 2200\\ Train Loss:4.542\\ Train Accuracy:0.253\n",
      "[2019/03/22 11:13:56] Epoch 3\\Batch 2400\\ Train Loss:4.539\\ Train Accuracy:0.253\n",
      "[2019/03/22 11:15:46] Epoch 3\\Batch 2600\\ Train Loss:4.537\\ Train Accuracy:0.253\n",
      "[2019/03/22 11:17:37] Epoch 3\\Batch 2800\\ Train Loss:4.535\\ Train Accuracy:0.253\n",
      "[2019/03/22 11:19:27] Epoch 3\\Batch 3000\\ Train Loss:4.534\\ Train Accuracy:0.253\n",
      "[2019/03/22 11:21:17] Epoch 3\\Batch 3200\\ Train Loss:4.532\\ Train Accuracy:0.253\n",
      "[2019/03/22 11:23:06] Epoch 3\\Batch 3400\\ Train Loss:4.531\\ Train Accuracy:0.253\n",
      "[2019/03/22 11:24:56] Epoch 3\\Batch 3600\\ Train Loss:4.529\\ Train Accuracy:0.253\n",
      "[2019/03/22 11:26:47] Epoch 3\\Batch 3800\\ Train Loss:4.526\\ Train Accuracy:0.254\n",
      "[2019/03/22 11:28:37] Epoch 3\\Batch 4000\\ Train Loss:4.524\\ Train Accuracy:0.254\n",
      "[2019/03/22 11:30:26] Epoch 3\\Batch 4200\\ Train Loss:4.521\\ Train Accuracy:0.254\n",
      "[2019/03/22 11:32:17] Epoch 3\\Batch 4400\\ Train Loss:4.518\\ Train Accuracy:0.254\n",
      "[2019/03/22 11:34:07] Epoch 3\\Batch 4600\\ Train Loss:4.515\\ Train Accuracy:0.255\n",
      "[2019/03/22 11:35:57] Epoch 3\\Batch 4800\\ Train Loss:4.512\\ Train Accuracy:0.255\n",
      "[2019/03/22 11:37:48] Epoch 3\\Batch 5000\\ Train Loss:4.510\\ Train Accuracy:0.255\n",
      "[2019/03/22 11:39:38] Epoch 3\\Batch 5200\\ Train Loss:4.508\\ Train Accuracy:0.255\n",
      "[2019/03/22 11:41:29] Epoch 3\\Batch 5400\\ Train Loss:4.506\\ Train Accuracy:0.255\n",
      "[2019/03/22 11:43:18] Epoch 3\\Batch 5600\\ Train Loss:4.504\\ Train Accuracy:0.256\n",
      "run model on validation data...\n",
      "[2019/03/22 11:45:00] Epoch 3\\ Validation Loss:4.505/ Validation Accuracy:0.251\n",
      "[2019/03/22 11:46:49] Epoch 4\\Batch 200\\ Train Loss:4.451\\ Train Accuracy:0.260\n",
      "[2019/03/22 11:48:40] Epoch 4\\Batch 400\\ Train Loss:4.446\\ Train Accuracy:0.262\n",
      "[2019/03/22 11:50:30] Epoch 4\\Batch 600\\ Train Loss:4.444\\ Train Accuracy:0.262\n",
      "[2019/03/22 11:52:20] Epoch 4\\Batch 800\\ Train Loss:4.444\\ Train Accuracy:0.261\n",
      "[2019/03/22 11:54:10] Epoch 4\\Batch 1000\\ Train Loss:4.442\\ Train Accuracy:0.261\n",
      "[2019/03/22 11:56:02] Epoch 4\\Batch 1200\\ Train Loss:4.437\\ Train Accuracy:0.262\n",
      "[2019/03/22 11:57:52] Epoch 4\\Batch 1400\\ Train Loss:4.433\\ Train Accuracy:0.263\n",
      "[2019/03/22 11:59:41] Epoch 4\\Batch 1600\\ Train Loss:4.429\\ Train Accuracy:0.263\n",
      "[2019/03/22 12:01:32] Epoch 4\\Batch 1800\\ Train Loss:4.427\\ Train Accuracy:0.263\n",
      "[2019/03/22 12:03:21] Epoch 4\\Batch 2000\\ Train Loss:4.424\\ Train Accuracy:0.264\n",
      "[2019/03/22 12:05:12] Epoch 4\\Batch 2200\\ Train Loss:4.420\\ Train Accuracy:0.264\n",
      "[2019/03/22 12:07:02] Epoch 4\\Batch 2400\\ Train Loss:4.418\\ Train Accuracy:0.264\n",
      "[2019/03/22 12:08:50] Epoch 4\\Batch 2600\\ Train Loss:4.416\\ Train Accuracy:0.264\n",
      "[2019/03/22 12:10:40] Epoch 4\\Batch 2800\\ Train Loss:4.414\\ Train Accuracy:0.264\n",
      "[2019/03/22 12:12:30] Epoch 4\\Batch 3000\\ Train Loss:4.413\\ Train Accuracy:0.264\n",
      "[2019/03/22 12:14:19] Epoch 4\\Batch 3200\\ Train Loss:4.412\\ Train Accuracy:0.264\n",
      "[2019/03/22 12:16:09] Epoch 4\\Batch 3400\\ Train Loss:4.411\\ Train Accuracy:0.265\n",
      "[2019/03/22 12:17:59] Epoch 4\\Batch 3600\\ Train Loss:4.409\\ Train Accuracy:0.265\n",
      "[2019/03/22 12:19:50] Epoch 4\\Batch 3800\\ Train Loss:4.408\\ Train Accuracy:0.265\n",
      "[2019/03/22 12:21:38] Epoch 4\\Batch 4000\\ Train Loss:4.406\\ Train Accuracy:0.265\n",
      "[2019/03/22 12:23:29] Epoch 4\\Batch 4200\\ Train Loss:4.405\\ Train Accuracy:0.265\n",
      "[2019/03/22 12:25:19] Epoch 4\\Batch 4400\\ Train Loss:4.403\\ Train Accuracy:0.265\n",
      "[2019/03/22 12:27:10] Epoch 4\\Batch 4600\\ Train Loss:4.400\\ Train Accuracy:0.266\n",
      "[2019/03/22 12:28:59] Epoch 4\\Batch 4800\\ Train Loss:4.398\\ Train Accuracy:0.266\n",
      "[2019/03/22 12:30:49] Epoch 4\\Batch 5000\\ Train Loss:4.396\\ Train Accuracy:0.266\n",
      "[2019/03/22 12:32:39] Epoch 4\\Batch 5200\\ Train Loss:4.395\\ Train Accuracy:0.266\n",
      "[2019/03/22 12:34:29] Epoch 4\\Batch 5400\\ Train Loss:4.393\\ Train Accuracy:0.266\n",
      "[2019/03/22 12:36:18] Epoch 4\\Batch 5600\\ Train Loss:4.392\\ Train Accuracy:0.267\n",
      "run model on validation data...\n",
      "[2019/03/22 12:37:59] Epoch 4\\ Validation Loss:4.418/ Validation Accuracy:0.257\n",
      "[2019/03/22 12:39:49] Epoch 5\\Batch 200\\ Train Loss:4.352\\ Train Accuracy:0.270\n",
      "[2019/03/22 12:41:38] Epoch 5\\Batch 400\\ Train Loss:4.347\\ Train Accuracy:0.272\n",
      "[2019/03/22 12:43:26] Epoch 5\\Batch 600\\ Train Loss:4.345\\ Train Accuracy:0.272\n",
      "[2019/03/22 12:45:16] Epoch 5\\Batch 800\\ Train Loss:4.345\\ Train Accuracy:0.272\n",
      "[2019/03/22 12:47:06] Epoch 5\\Batch 1000\\ Train Loss:4.347\\ Train Accuracy:0.271\n",
      "[2019/03/22 12:48:57] Epoch 5\\Batch 1200\\ Train Loss:4.346\\ Train Accuracy:0.272\n",
      "[2019/03/22 12:50:47] Epoch 5\\Batch 1400\\ Train Loss:4.343\\ Train Accuracy:0.272\n",
      "[2019/03/22 12:52:37] Epoch 5\\Batch 1600\\ Train Loss:4.340\\ Train Accuracy:0.272\n",
      "[2019/03/22 12:54:27] Epoch 5\\Batch 1800\\ Train Loss:4.337\\ Train Accuracy:0.273\n",
      "[2019/03/22 12:56:16] Epoch 5\\Batch 2000\\ Train Loss:4.335\\ Train Accuracy:0.273\n",
      "[2019/03/22 12:58:06] Epoch 5\\Batch 2200\\ Train Loss:4.331\\ Train Accuracy:0.273\n",
      "[2019/03/22 12:59:56] Epoch 5\\Batch 2400\\ Train Loss:4.329\\ Train Accuracy:0.273\n",
      "[2019/03/22 13:01:45] Epoch 5\\Batch 2600\\ Train Loss:4.328\\ Train Accuracy:0.273\n",
      "[2019/03/22 13:03:35] Epoch 5\\Batch 2800\\ Train Loss:4.326\\ Train Accuracy:0.273\n",
      "[2019/03/22 13:05:24] Epoch 5\\Batch 3000\\ Train Loss:4.325\\ Train Accuracy:0.273\n",
      "[2019/03/22 13:07:14] Epoch 5\\Batch 3200\\ Train Loss:4.324\\ Train Accuracy:0.273\n",
      "[2019/03/22 13:09:05] Epoch 5\\Batch 3400\\ Train Loss:4.323\\ Train Accuracy:0.274\n",
      "[2019/03/22 13:10:54] Epoch 5\\Batch 3600\\ Train Loss:4.322\\ Train Accuracy:0.274\n",
      "[2019/03/22 13:12:42] Epoch 5\\Batch 3800\\ Train Loss:4.321\\ Train Accuracy:0.274\n",
      "[2019/03/22 13:14:32] Epoch 5\\Batch 4000\\ Train Loss:4.320\\ Train Accuracy:0.274\n",
      "[2019/03/22 13:16:22] Epoch 5\\Batch 4200\\ Train Loss:4.319\\ Train Accuracy:0.274\n",
      "[2019/03/22 13:18:12] Epoch 5\\Batch 4400\\ Train Loss:4.318\\ Train Accuracy:0.274\n",
      "[2019/03/22 13:20:04] Epoch 5\\Batch 4600\\ Train Loss:4.316\\ Train Accuracy:0.274\n",
      "[2019/03/22 13:21:53] Epoch 5\\Batch 4800\\ Train Loss:4.314\\ Train Accuracy:0.274\n",
      "[2019/03/22 13:23:41] Epoch 5\\Batch 5000\\ Train Loss:4.313\\ Train Accuracy:0.275\n",
      "[2019/03/22 13:25:29] Epoch 5\\Batch 5200\\ Train Loss:4.311\\ Train Accuracy:0.275\n",
      "[2019/03/22 13:27:20] Epoch 5\\Batch 5400\\ Train Loss:4.310\\ Train Accuracy:0.275\n",
      "[2019/03/22 13:29:10] Epoch 5\\Batch 5600\\ Train Loss:4.309\\ Train Accuracy:0.275\n",
      "run model on validation data...\n",
      "[2019/03/22 13:30:52] Epoch 5\\ Validation Loss:4.342/ Validation Accuracy:0.263\n",
      "[2019/03/22 13:32:41] Epoch 6\\Batch 200\\ Train Loss:4.277\\ Train Accuracy:0.278\n",
      "[2019/03/22 13:34:31] Epoch 6\\Batch 400\\ Train Loss:4.271\\ Train Accuracy:0.279\n",
      "[2019/03/22 13:36:21] Epoch 6\\Batch 600\\ Train Loss:4.269\\ Train Accuracy:0.279\n",
      "[2019/03/22 13:38:11] Epoch 6\\Batch 800\\ Train Loss:4.267\\ Train Accuracy:0.279\n",
      "[2019/03/22 13:40:00] Epoch 6\\Batch 1000\\ Train Loss:4.267\\ Train Accuracy:0.279\n",
      "[2019/03/22 13:41:50] Epoch 6\\Batch 1200\\ Train Loss:4.267\\ Train Accuracy:0.279\n",
      "[2019/03/22 13:43:41] Epoch 6\\Batch 1400\\ Train Loss:4.267\\ Train Accuracy:0.279\n",
      "[2019/03/22 13:45:31] Epoch 6\\Batch 1600\\ Train Loss:4.266\\ Train Accuracy:0.280\n",
      "[2019/03/22 13:47:21] Epoch 6\\Batch 1800\\ Train Loss:4.264\\ Train Accuracy:0.280\n",
      "[2019/03/22 13:49:11] Epoch 6\\Batch 2000\\ Train Loss:4.262\\ Train Accuracy:0.280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/22 13:51:00] Epoch 6\\Batch 2200\\ Train Loss:4.259\\ Train Accuracy:0.280\n",
      "[2019/03/22 13:52:50] Epoch 6\\Batch 2400\\ Train Loss:4.258\\ Train Accuracy:0.280\n",
      "[2019/03/22 13:54:40] Epoch 6\\Batch 2600\\ Train Loss:4.256\\ Train Accuracy:0.280\n",
      "[2019/03/22 13:56:32] Epoch 6\\Batch 2800\\ Train Loss:4.255\\ Train Accuracy:0.280\n",
      "[2019/03/22 13:58:22] Epoch 6\\Batch 3000\\ Train Loss:4.255\\ Train Accuracy:0.280\n",
      "[2019/03/22 14:00:12] Epoch 6\\Batch 3200\\ Train Loss:4.254\\ Train Accuracy:0.280\n",
      "[2019/03/22 14:02:03] Epoch 6\\Batch 3400\\ Train Loss:4.253\\ Train Accuracy:0.280\n",
      "[2019/03/22 14:03:53] Epoch 6\\Batch 3600\\ Train Loss:4.251\\ Train Accuracy:0.281\n",
      "[2019/03/22 14:05:43] Epoch 6\\Batch 3800\\ Train Loss:4.250\\ Train Accuracy:0.281\n",
      "[2019/03/22 14:07:33] Epoch 6\\Batch 4000\\ Train Loss:4.249\\ Train Accuracy:0.281\n",
      "[2019/03/22 14:09:23] Epoch 6\\Batch 4200\\ Train Loss:4.249\\ Train Accuracy:0.281\n",
      "[2019/03/22 14:11:13] Epoch 6\\Batch 4400\\ Train Loss:4.249\\ Train Accuracy:0.281\n",
      "[2019/03/22 14:13:01] Epoch 6\\Batch 4600\\ Train Loss:4.248\\ Train Accuracy:0.281\n",
      "[2019/03/22 14:14:51] Epoch 6\\Batch 4800\\ Train Loss:4.247\\ Train Accuracy:0.281\n",
      "[2019/03/22 14:16:40] Epoch 6\\Batch 5000\\ Train Loss:4.246\\ Train Accuracy:0.281\n",
      "[2019/03/22 14:18:30] Epoch 6\\Batch 5200\\ Train Loss:4.245\\ Train Accuracy:0.281\n",
      "[2019/03/22 14:20:20] Epoch 6\\Batch 5400\\ Train Loss:4.244\\ Train Accuracy:0.281\n",
      "[2019/03/22 14:22:13] Epoch 6\\Batch 5600\\ Train Loss:4.243\\ Train Accuracy:0.281\n",
      "run model on validation data...\n",
      "[2019/03/22 14:23:54] Epoch 6\\ Validation Loss:4.295/ Validation Accuracy:0.268\n",
      "[2019/03/22 14:25:42] Epoch 7\\Batch 200\\ Train Loss:4.221\\ Train Accuracy:0.283\n",
      "[2019/03/22 14:27:31] Epoch 7\\Batch 400\\ Train Loss:4.216\\ Train Accuracy:0.285\n",
      "[2019/03/22 14:29:22] Epoch 7\\Batch 600\\ Train Loss:4.212\\ Train Accuracy:0.285\n",
      "[2019/03/22 14:31:12] Epoch 7\\Batch 800\\ Train Loss:4.210\\ Train Accuracy:0.285\n",
      "[2019/03/22 14:33:05] Epoch 7\\Batch 1000\\ Train Loss:4.210\\ Train Accuracy:0.285\n",
      "[2019/03/22 14:35:01] Epoch 7\\Batch 1200\\ Train Loss:4.210\\ Train Accuracy:0.285\n",
      "[2019/03/22 14:36:59] Epoch 7\\Batch 1400\\ Train Loss:4.210\\ Train Accuracy:0.285\n",
      "[2019/03/22 14:38:57] Epoch 7\\Batch 1600\\ Train Loss:4.210\\ Train Accuracy:0.285\n",
      "[2019/03/22 14:40:55] Epoch 7\\Batch 1800\\ Train Loss:4.209\\ Train Accuracy:0.285\n",
      "[2019/03/22 14:42:52] Epoch 7\\Batch 2000\\ Train Loss:4.207\\ Train Accuracy:0.286\n",
      "[2019/03/22 14:44:50] Epoch 7\\Batch 2200\\ Train Loss:4.205\\ Train Accuracy:0.286\n",
      "[2019/03/22 14:46:45] Epoch 7\\Batch 2400\\ Train Loss:4.204\\ Train Accuracy:0.286\n",
      "[2019/03/22 14:48:41] Epoch 7\\Batch 2600\\ Train Loss:4.203\\ Train Accuracy:0.286\n",
      "[2019/03/22 14:50:40] Epoch 7\\Batch 2800\\ Train Loss:4.202\\ Train Accuracy:0.286\n",
      "[2019/03/22 14:52:36] Epoch 7\\Batch 3000\\ Train Loss:4.202\\ Train Accuracy:0.286\n",
      "[2019/03/22 14:54:33] Epoch 7\\Batch 3200\\ Train Loss:4.201\\ Train Accuracy:0.286\n",
      "[2019/03/22 14:56:30] Epoch 7\\Batch 3400\\ Train Loss:4.200\\ Train Accuracy:0.286\n",
      "[2019/03/22 14:58:28] Epoch 7\\Batch 3600\\ Train Loss:4.199\\ Train Accuracy:0.286\n",
      "[2019/03/22 15:00:26] Epoch 7\\Batch 3800\\ Train Loss:4.198\\ Train Accuracy:0.286\n",
      "[2019/03/22 15:02:23] Epoch 7\\Batch 4000\\ Train Loss:4.197\\ Train Accuracy:0.286\n",
      "[2019/03/22 15:04:20] Epoch 7\\Batch 4200\\ Train Loss:4.197\\ Train Accuracy:0.286\n",
      "[2019/03/22 15:06:18] Epoch 7\\Batch 4400\\ Train Loss:4.196\\ Train Accuracy:0.286\n",
      "[2019/03/22 15:08:16] Epoch 7\\Batch 4600\\ Train Loss:4.195\\ Train Accuracy:0.286\n",
      "[2019/03/22 15:10:14] Epoch 7\\Batch 4800\\ Train Loss:4.195\\ Train Accuracy:0.286\n",
      "[2019/03/22 15:12:10] Epoch 7\\Batch 5000\\ Train Loss:4.194\\ Train Accuracy:0.286\n",
      "[2019/03/22 15:14:08] Epoch 7\\Batch 5200\\ Train Loss:4.193\\ Train Accuracy:0.286\n",
      "[2019/03/22 15:16:07] Epoch 7\\Batch 5400\\ Train Loss:4.193\\ Train Accuracy:0.286\n",
      "[2019/03/22 15:18:04] Epoch 7\\Batch 5600\\ Train Loss:4.192\\ Train Accuracy:0.287\n",
      "run model on validation data...\n",
      "[2019/03/22 15:19:53] Epoch 7\\ Validation Loss:4.258/ Validation Accuracy:0.275\n",
      "[2019/03/22 15:21:49] Epoch 8\\Batch 200\\ Train Loss:4.177\\ Train Accuracy:0.287\n",
      "[2019/03/22 15:23:44] Epoch 8\\Batch 400\\ Train Loss:4.173\\ Train Accuracy:0.289\n",
      "[2019/03/22 15:25:41] Epoch 8\\Batch 600\\ Train Loss:4.170\\ Train Accuracy:0.289\n",
      "[2019/03/22 15:27:36] Epoch 8\\Batch 800\\ Train Loss:4.167\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:29:30] Epoch 8\\Batch 1000\\ Train Loss:4.167\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:31:24] Epoch 8\\Batch 1200\\ Train Loss:4.167\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:33:19] Epoch 8\\Batch 1400\\ Train Loss:4.168\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:35:14] Epoch 8\\Batch 1600\\ Train Loss:4.167\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:37:08] Epoch 8\\Batch 1800\\ Train Loss:4.167\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:39:03] Epoch 8\\Batch 2000\\ Train Loss:4.167\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:40:57] Epoch 8\\Batch 2200\\ Train Loss:4.165\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:42:51] Epoch 8\\Batch 2400\\ Train Loss:4.164\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:44:46] Epoch 8\\Batch 2600\\ Train Loss:4.163\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:46:41] Epoch 8\\Batch 2800\\ Train Loss:4.163\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:48:36] Epoch 8\\Batch 3000\\ Train Loss:4.162\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:50:30] Epoch 8\\Batch 3200\\ Train Loss:4.162\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:52:23] Epoch 8\\Batch 3400\\ Train Loss:4.161\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:54:17] Epoch 8\\Batch 3600\\ Train Loss:4.160\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:56:12] Epoch 8\\Batch 3800\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/22 15:58:08] Epoch 8\\Batch 4000\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/22 16:00:03] Epoch 8\\Batch 4200\\ Train Loss:4.158\\ Train Accuracy:0.290\n",
      "[2019/03/22 16:01:59] Epoch 8\\Batch 4400\\ Train Loss:4.158\\ Train Accuracy:0.290\n",
      "[2019/03/22 16:03:53] Epoch 8\\Batch 4600\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/22 16:05:48] Epoch 8\\Batch 4800\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/22 16:07:42] Epoch 8\\Batch 5000\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/22 16:09:37] Epoch 8\\Batch 5200\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/22 16:11:31] Epoch 8\\Batch 5400\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/22 16:13:22] Epoch 8\\Batch 5600\\ Train Loss:4.155\\ Train Accuracy:0.290\n",
      "run model on validation data...\n",
      "[2019/03/22 16:15:02] Epoch 8\\ Validation Loss:4.238/ Validation Accuracy:0.277\n",
      "[2019/03/22 16:16:53] Epoch 9\\Batch 200\\ Train Loss:4.147\\ Train Accuracy:0.290\n",
      "[2019/03/22 16:18:44] Epoch 9\\Batch 400\\ Train Loss:4.143\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:20:34] Epoch 9\\Batch 600\\ Train Loss:4.140\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:22:24] Epoch 9\\Batch 800\\ Train Loss:4.137\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:24:13] Epoch 9\\Batch 1000\\ Train Loss:4.137\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:26:03] Epoch 9\\Batch 1200\\ Train Loss:4.137\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:27:53] Epoch 9\\Batch 1400\\ Train Loss:4.137\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:29:23] Epoch 9\\Batch 1600\\ Train Loss:4.137\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:30:48] Epoch 9\\Batch 1800\\ Train Loss:4.136\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:32:11] Epoch 9\\Batch 2000\\ Train Loss:4.136\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:33:42] Epoch 9\\Batch 2200\\ Train Loss:4.135\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:35:04] Epoch 9\\Batch 2400\\ Train Loss:4.135\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:36:29] Epoch 9\\Batch 2600\\ Train Loss:4.134\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:38:13] Epoch 9\\Batch 2800\\ Train Loss:4.134\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:40:04] Epoch 9\\Batch 3000\\ Train Loss:4.134\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:41:54] Epoch 9\\Batch 3200\\ Train Loss:4.133\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:43:45] Epoch 9\\Batch 3400\\ Train Loss:4.133\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:45:37] Epoch 9\\Batch 3600\\ Train Loss:4.132\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:47:26] Epoch 9\\Batch 3800\\ Train Loss:4.131\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:49:16] Epoch 9\\Batch 4000\\ Train Loss:4.131\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:51:07] Epoch 9\\Batch 4200\\ Train Loss:4.130\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:52:57] Epoch 9\\Batch 4400\\ Train Loss:4.130\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:54:47] Epoch 9\\Batch 4600\\ Train Loss:4.129\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:56:38] Epoch 9\\Batch 4800\\ Train Loss:4.129\\ Train Accuracy:0.293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/22 16:58:24] Epoch 9\\Batch 5000\\ Train Loss:4.129\\ Train Accuracy:0.293\n",
      "[2019/03/22 16:59:54] Epoch 9\\Batch 5200\\ Train Loss:4.129\\ Train Accuracy:0.293\n",
      "[2019/03/22 17:01:23] Epoch 9\\Batch 5400\\ Train Loss:4.128\\ Train Accuracy:0.293\n",
      "[2019/03/22 17:02:47] Epoch 9\\Batch 5600\\ Train Loss:4.128\\ Train Accuracy:0.293\n",
      "run model on validation data...\n",
      "[2019/03/22 17:04:10] Epoch 9\\ Validation Loss:4.222/ Validation Accuracy:0.279\n",
      "[2019/03/22 17:04:12] Validation Loss:4.222\\ Validation Accuracy:0.279\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache files exist, going to load in...\n",
      "loading h5_file...\n",
      "h5_file.keys: KeysView(<HDF5 file \"data.h5\" (mode r)>)\n",
      "loading pickle file\n",
      "cache files load successful!\n",
      "train_X.shape: (2959966, 200)\n",
      "train_y.shape: (2959966,)\n",
      "test_X.shape: (20000, 200)\n",
      "test_y.shape: (20000,)\n",
      "test_X[0]: [ 579  343 1173 1843    5  583  292 1173 1843    5 1180 1299  989   10\n",
      "    2   68  153  168  531  109  260  217  277   81   59   81  116  514\n",
      "    6  221  253  224  154  718  553    4  806  538  732  264   74    6\n",
      "  221  224  154  326   11  167  136    4  257  145   37   74  175  214\n",
      "   11   57  110  221    6  364   89   20 4050 2344    4  257   78    9\n",
      "  991  326  221   89  699  133   11  597  679 1957  824  884  871 1957\n",
      "  824    4  178   87   87   78  196   52  552   69   47   20   12   37\n",
      " 1371   89    6  755  779   81  667  597    4  586  878    6   35   93\n",
      "    7  719  285  937   35  162   13   11    7 1371   89   35    4  201\n",
      "   68   81   97 1533   81  667  597    9  991  326   35  343  704   16\n",
      "    5   99   13    9  991  654  583  292    4   13  221    6  795  230\n",
      "   11   11  350   12  495  235    7  990  625  718  553  297  215  954\n",
      "  549    4   12  165  198   67   93    9  166  110  146    4   81   86\n",
      "   93  141   87 1146  118  224  154   93  147    9   20    4   81  407\n",
      "   92  116  514   12]\n",
      "test_y[0]: 808\n",
      "[2019/03/23 08:30:56] restore from checkpoint\n",
      "INFO:tensorflow:Restoring parameters from testrnn_singlelabel_checkpoint/model.ckpt-9\n",
      "[2019/03/23 08:30:56] continue training...\n",
      "[2019/03/23 08:32:49] Epoch 9\\Batch 200\\ Train Loss:4.126\\ Train Accuracy:0.292\n",
      "[2019/03/23 08:34:40] Epoch 9\\Batch 400\\ Train Loss:4.122\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:36:31] Epoch 9\\Batch 600\\ Train Loss:4.118\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:38:22] Epoch 9\\Batch 800\\ Train Loss:4.115\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:40:12] Epoch 9\\Batch 1000\\ Train Loss:4.115\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:42:05] Epoch 9\\Batch 1200\\ Train Loss:4.115\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:43:56] Epoch 9\\Batch 1400\\ Train Loss:4.115\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:45:46] Epoch 9\\Batch 1600\\ Train Loss:4.115\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:47:38] Epoch 9\\Batch 1800\\ Train Loss:4.114\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:49:29] Epoch 9\\Batch 2000\\ Train Loss:4.114\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:51:19] Epoch 9\\Batch 2200\\ Train Loss:4.113\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:53:06] Epoch 9\\Batch 2400\\ Train Loss:4.113\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:54:47] Epoch 9\\Batch 2600\\ Train Loss:4.113\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:56:37] Epoch 9\\Batch 2800\\ Train Loss:4.113\\ Train Accuracy:0.295\n",
      "[2019/03/23 08:58:29] Epoch 9\\Batch 3000\\ Train Loss:4.113\\ Train Accuracy:0.295\n",
      "[2019/03/23 09:00:19] Epoch 9\\Batch 3200\\ Train Loss:4.113\\ Train Accuracy:0.295\n",
      "[2019/03/23 09:02:11] Epoch 9\\Batch 3400\\ Train Loss:4.113\\ Train Accuracy:0.295\n",
      "[2019/03/23 09:04:01] Epoch 9\\Batch 3600\\ Train Loss:4.112\\ Train Accuracy:0.295\n",
      "[2019/03/23 09:05:51] Epoch 9\\Batch 3800\\ Train Loss:4.111\\ Train Accuracy:0.296\n",
      "[2019/03/23 09:07:41] Epoch 9\\Batch 4000\\ Train Loss:4.110\\ Train Accuracy:0.296\n",
      "[2019/03/23 09:09:33] Epoch 9\\Batch 4200\\ Train Loss:4.110\\ Train Accuracy:0.295\n",
      "[2019/03/23 09:11:24] Epoch 9\\Batch 4400\\ Train Loss:4.110\\ Train Accuracy:0.296\n",
      "[2019/03/23 09:13:15] Epoch 9\\Batch 4600\\ Train Loss:4.109\\ Train Accuracy:0.296\n",
      "[2019/03/23 09:15:05] Epoch 9\\Batch 4800\\ Train Loss:4.109\\ Train Accuracy:0.296\n",
      "[2019/03/23 09:17:00] Epoch 9\\Batch 5000\\ Train Loss:4.109\\ Train Accuracy:0.296\n",
      "[2019/03/23 09:18:54] Epoch 9\\Batch 5200\\ Train Loss:4.109\\ Train Accuracy:0.296\n",
      "[2019/03/23 09:20:34] Epoch 9\\Batch 5400\\ Train Loss:4.109\\ Train Accuracy:0.296\n",
      "[2019/03/23 09:22:28] Epoch 9\\Batch 5600\\ Train Loss:4.109\\ Train Accuracy:0.296\n",
      "run model on validation data...\n",
      "[2019/03/23 09:24:13] Epoch 9\\ Validation Loss:4.212/ Validation Accuracy:0.282\n",
      "[2019/03/23 09:26:08] Epoch 10\\Batch 200\\ Train Loss:4.111\\ Train Accuracy:0.295\n",
      "[2019/03/23 09:28:02] Epoch 10\\Batch 400\\ Train Loss:4.107\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:29:56] Epoch 10\\Batch 600\\ Train Loss:4.103\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:31:47] Epoch 10\\Batch 800\\ Train Loss:4.100\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:33:37] Epoch 10\\Batch 1000\\ Train Loss:4.100\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:35:29] Epoch 10\\Batch 1200\\ Train Loss:4.100\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:37:20] Epoch 10\\Batch 1400\\ Train Loss:4.100\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:39:11] Epoch 10\\Batch 1600\\ Train Loss:4.100\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:41:01] Epoch 10\\Batch 1800\\ Train Loss:4.099\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:42:51] Epoch 10\\Batch 2000\\ Train Loss:4.099\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:44:43] Epoch 10\\Batch 2200\\ Train Loss:4.097\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:46:33] Epoch 10\\Batch 2400\\ Train Loss:4.098\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:48:19] Epoch 10\\Batch 2600\\ Train Loss:4.097\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:50:02] Epoch 10\\Batch 2800\\ Train Loss:4.098\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:51:54] Epoch 10\\Batch 3000\\ Train Loss:4.098\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:53:45] Epoch 10\\Batch 3200\\ Train Loss:4.098\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:55:36] Epoch 10\\Batch 3400\\ Train Loss:4.098\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:57:26] Epoch 10\\Batch 3600\\ Train Loss:4.097\\ Train Accuracy:0.297\n",
      "[2019/03/23 09:59:18] Epoch 10\\Batch 3800\\ Train Loss:4.096\\ Train Accuracy:0.297\n",
      "[2019/03/23 10:01:08] Epoch 10\\Batch 4000\\ Train Loss:4.096\\ Train Accuracy:0.297\n",
      "[2019/03/23 10:03:00] Epoch 10\\Batch 4200\\ Train Loss:4.096\\ Train Accuracy:0.297\n",
      "[2019/03/23 10:04:51] Epoch 10\\Batch 4400\\ Train Loss:4.096\\ Train Accuracy:0.297\n",
      "[2019/03/23 10:06:43] Epoch 10\\Batch 4600\\ Train Loss:4.095\\ Train Accuracy:0.297\n",
      "[2019/03/23 10:08:34] Epoch 10\\Batch 4800\\ Train Loss:4.095\\ Train Accuracy:0.297\n",
      "[2019/03/23 10:10:23] Epoch 10\\Batch 5000\\ Train Loss:4.095\\ Train Accuracy:0.297\n",
      "[2019/03/23 10:12:13] Epoch 10\\Batch 5200\\ Train Loss:4.095\\ Train Accuracy:0.297\n",
      "[2019/03/23 10:14:03] Epoch 10\\Batch 5400\\ Train Loss:4.095\\ Train Accuracy:0.297\n",
      "[2019/03/23 10:15:40] Epoch 10\\Batch 5600\\ Train Loss:4.095\\ Train Accuracy:0.297\n",
      "run model on validation data...\n",
      "[2019/03/23 10:17:24] Epoch 10\\ Validation Loss:4.206/ Validation Accuracy:0.286\n",
      "[2019/03/23 10:19:16] Epoch 11\\Batch 200\\ Train Loss:4.100\\ Train Accuracy:0.296\n",
      "[2019/03/23 10:21:07] Epoch 11\\Batch 400\\ Train Loss:4.096\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:22:57] Epoch 11\\Batch 600\\ Train Loss:4.093\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:24:49] Epoch 11\\Batch 800\\ Train Loss:4.090\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:26:40] Epoch 11\\Batch 1000\\ Train Loss:4.090\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:28:32] Epoch 11\\Batch 1200\\ Train Loss:4.089\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:30:23] Epoch 11\\Batch 1400\\ Train Loss:4.090\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:32:13] Epoch 11\\Batch 1600\\ Train Loss:4.089\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:34:05] Epoch 11\\Batch 1800\\ Train Loss:4.089\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:35:55] Epoch 11\\Batch 2000\\ Train Loss:4.088\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:37:45] Epoch 11\\Batch 2200\\ Train Loss:4.087\\ Train Accuracy:0.299\n",
      "[2019/03/23 10:39:37] Epoch 11\\Batch 2400\\ Train Loss:4.087\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:41:28] Epoch 11\\Batch 2600\\ Train Loss:4.087\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:43:10] Epoch 11\\Batch 2800\\ Train Loss:4.087\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:44:57] Epoch 11\\Batch 3000\\ Train Loss:4.087\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:46:48] Epoch 11\\Batch 3200\\ Train Loss:4.088\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:48:39] Epoch 11\\Batch 3400\\ Train Loss:4.088\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:50:31] Epoch 11\\Batch 3600\\ Train Loss:4.087\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:52:20] Epoch 11\\Batch 3800\\ Train Loss:4.086\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:54:11] Epoch 11\\Batch 4000\\ Train Loss:4.086\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:56:01] Epoch 11\\Batch 4200\\ Train Loss:4.086\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:57:52] Epoch 11\\Batch 4400\\ Train Loss:4.086\\ Train Accuracy:0.298\n",
      "[2019/03/23 10:59:44] Epoch 11\\Batch 4600\\ Train Loss:4.085\\ Train Accuracy:0.298\n",
      "[2019/03/23 11:01:34] Epoch 11\\Batch 4800\\ Train Loss:4.085\\ Train Accuracy:0.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/23 11:03:25] Epoch 11\\Batch 5000\\ Train Loss:4.085\\ Train Accuracy:0.298\n",
      "[2019/03/23 11:05:16] Epoch 11\\Batch 5200\\ Train Loss:4.085\\ Train Accuracy:0.298\n",
      "[2019/03/23 11:07:07] Epoch 11\\Batch 5400\\ Train Loss:4.085\\ Train Accuracy:0.298\n",
      "[2019/03/23 11:08:57] Epoch 11\\Batch 5600\\ Train Loss:4.085\\ Train Accuracy:0.298\n",
      "run model on validation data...\n",
      "[2019/03/23 11:10:28] Epoch 11\\ Validation Loss:4.203/ Validation Accuracy:0.286\n",
      "[2019/03/23 11:12:20] Epoch 12\\Batch 200\\ Train Loss:4.093\\ Train Accuracy:0.297\n",
      "[2019/03/23 11:14:11] Epoch 12\\Batch 400\\ Train Loss:4.089\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:16:02] Epoch 12\\Batch 600\\ Train Loss:4.086\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:17:53] Epoch 12\\Batch 800\\ Train Loss:4.083\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:19:42] Epoch 12\\Batch 1000\\ Train Loss:4.083\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:21:33] Epoch 12\\Batch 1200\\ Train Loss:4.082\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:23:24] Epoch 12\\Batch 1400\\ Train Loss:4.083\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:25:16] Epoch 12\\Batch 1600\\ Train Loss:4.082\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:27:06] Epoch 12\\Batch 1800\\ Train Loss:4.082\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:28:57] Epoch 12\\Batch 2000\\ Train Loss:4.081\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:30:48] Epoch 12\\Batch 2200\\ Train Loss:4.080\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:32:37] Epoch 12\\Batch 2400\\ Train Loss:4.079\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:34:27] Epoch 12\\Batch 2600\\ Train Loss:4.079\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:36:17] Epoch 12\\Batch 2800\\ Train Loss:4.080\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:37:59] Epoch 12\\Batch 3000\\ Train Loss:4.080\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:39:49] Epoch 12\\Batch 3200\\ Train Loss:4.081\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:41:39] Epoch 12\\Batch 3400\\ Train Loss:4.081\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:43:30] Epoch 12\\Batch 3600\\ Train Loss:4.080\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:45:21] Epoch 12\\Batch 3800\\ Train Loss:4.079\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:47:11] Epoch 12\\Batch 4000\\ Train Loss:4.079\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:49:01] Epoch 12\\Batch 4200\\ Train Loss:4.079\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:50:52] Epoch 12\\Batch 4400\\ Train Loss:4.079\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:52:44] Epoch 12\\Batch 4600\\ Train Loss:4.079\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:54:35] Epoch 12\\Batch 4800\\ Train Loss:4.078\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:56:25] Epoch 12\\Batch 5000\\ Train Loss:4.078\\ Train Accuracy:0.299\n",
      "[2019/03/23 11:58:16] Epoch 12\\Batch 5200\\ Train Loss:4.078\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:00:06] Epoch 12\\Batch 5400\\ Train Loss:4.078\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:01:57] Epoch 12\\Batch 5600\\ Train Loss:4.078\\ Train Accuracy:0.299\n",
      "run model on validation data...\n",
      "[2019/03/23 12:03:40] Epoch 12\\ Validation Loss:4.201/ Validation Accuracy:0.288\n",
      "[2019/03/23 12:05:17] Epoch 13\\Batch 200\\ Train Loss:4.089\\ Train Accuracy:0.297\n",
      "[2019/03/23 12:07:08] Epoch 13\\Batch 400\\ Train Loss:4.085\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:08:59] Epoch 13\\Batch 600\\ Train Loss:4.081\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:10:49] Epoch 13\\Batch 800\\ Train Loss:4.078\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:12:40] Epoch 13\\Batch 1000\\ Train Loss:4.078\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:14:31] Epoch 13\\Batch 1200\\ Train Loss:4.078\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:16:23] Epoch 13\\Batch 1400\\ Train Loss:4.078\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:18:18] Epoch 13\\Batch 1600\\ Train Loss:4.077\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:20:14] Epoch 13\\Batch 1800\\ Train Loss:4.077\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:22:08] Epoch 13\\Batch 2000\\ Train Loss:4.076\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:24:03] Epoch 13\\Batch 2200\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:25:59] Epoch 13\\Batch 2400\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:27:54] Epoch 13\\Batch 2600\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:29:51] Epoch 13\\Batch 2800\\ Train Loss:4.075\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:31:43] Epoch 13\\Batch 3000\\ Train Loss:4.075\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:33:20] Epoch 13\\Batch 3200\\ Train Loss:4.076\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:35:11] Epoch 13\\Batch 3400\\ Train Loss:4.076\\ Train Accuracy:0.299\n",
      "[2019/03/23 12:37:01] Epoch 13\\Batch 3600\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:38:51] Epoch 13\\Batch 3800\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:40:42] Epoch 13\\Batch 4000\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:42:31] Epoch 13\\Batch 4200\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:44:22] Epoch 13\\Batch 4400\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:46:14] Epoch 13\\Batch 4600\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:48:05] Epoch 13\\Batch 4800\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:49:55] Epoch 13\\Batch 5000\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:51:45] Epoch 13\\Batch 5200\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:53:37] Epoch 13\\Batch 5400\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "[2019/03/23 12:55:27] Epoch 13\\Batch 5600\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "run model on validation data...\n",
      "[2019/03/23 12:57:09] Epoch 13\\ Validation Loss:4.200/ Validation Accuracy:0.288\n",
      "[2019/03/23 12:58:59] Epoch 14\\Batch 200\\ Train Loss:4.085\\ Train Accuracy:0.298\n",
      "[2019/03/23 13:00:37] Epoch 14\\Batch 400\\ Train Loss:4.081\\ Train Accuracy:0.299\n",
      "[2019/03/23 13:02:31] Epoch 14\\Batch 600\\ Train Loss:4.078\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:04:26] Epoch 14\\Batch 800\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:06:21] Epoch 14\\Batch 1000\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:08:14] Epoch 14\\Batch 1200\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:10:08] Epoch 14\\Batch 1400\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:12:03] Epoch 14\\Batch 1600\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:13:57] Epoch 14\\Batch 1800\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:15:48] Epoch 14\\Batch 2000\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:17:38] Epoch 14\\Batch 2200\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:19:30] Epoch 14\\Batch 2400\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:21:21] Epoch 14\\Batch 2600\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:23:11] Epoch 14\\Batch 2800\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:25:02] Epoch 14\\Batch 3000\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:26:51] Epoch 14\\Batch 3200\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:28:29] Epoch 14\\Batch 3400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:30:21] Epoch 14\\Batch 3600\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:32:12] Epoch 14\\Batch 3800\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:34:02] Epoch 14\\Batch 4000\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:35:52] Epoch 14\\Batch 4200\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:37:43] Epoch 14\\Batch 4400\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:39:38] Epoch 14\\Batch 4600\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:41:33] Epoch 14\\Batch 4800\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:43:28] Epoch 14\\Batch 5000\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:45:23] Epoch 14\\Batch 5200\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:47:19] Epoch 14\\Batch 5400\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:49:16] Epoch 14\\Batch 5600\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "run model on validation data...\n",
      "[2019/03/23 13:51:03] Epoch 14\\ Validation Loss:4.200/ Validation Accuracy:0.288\n",
      "[2019/03/23 13:52:58] Epoch 15\\Batch 200\\ Train Loss:4.082\\ Train Accuracy:0.298\n",
      "[2019/03/23 13:54:51] Epoch 15\\Batch 400\\ Train Loss:4.078\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:56:31] Epoch 15\\Batch 600\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 13:58:26] Epoch 15\\Batch 800\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:00:22] Epoch 15\\Batch 1000\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:02:15] Epoch 15\\Batch 1200\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:04:10] Epoch 15\\Batch 1400\\ Train Loss:4.073\\ Train Accuracy:0.300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/23 14:06:05] Epoch 15\\Batch 1600\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:08:01] Epoch 15\\Batch 1800\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:09:55] Epoch 15\\Batch 2000\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:11:45] Epoch 15\\Batch 2200\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:13:37] Epoch 15\\Batch 2400\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:15:32] Epoch 15\\Batch 2600\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:17:25] Epoch 15\\Batch 2800\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:19:22] Epoch 15\\Batch 3000\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:21:19] Epoch 15\\Batch 3200\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:23:15] Epoch 15\\Batch 3400\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:24:57] Epoch 15\\Batch 3600\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:26:53] Epoch 15\\Batch 3800\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:28:44] Epoch 15\\Batch 4000\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:30:35] Epoch 15\\Batch 4200\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:32:25] Epoch 15\\Batch 4400\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:34:17] Epoch 15\\Batch 4600\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:36:10] Epoch 15\\Batch 4800\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:38:06] Epoch 15\\Batch 5000\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:40:02] Epoch 15\\Batch 5200\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:41:59] Epoch 15\\Batch 5400\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:43:54] Epoch 15\\Batch 5600\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "run model on validation data...\n",
      "[2019/03/23 14:45:40] Epoch 15\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/23 14:47:37] Epoch 16\\Batch 200\\ Train Loss:4.080\\ Train Accuracy:0.298\n",
      "[2019/03/23 14:49:32] Epoch 16\\Batch 400\\ Train Loss:4.076\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:51:21] Epoch 16\\Batch 600\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:53:02] Epoch 16\\Batch 800\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:54:52] Epoch 16\\Batch 1000\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:56:43] Epoch 16\\Batch 1200\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 14:58:36] Epoch 16\\Batch 1400\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:00:29] Epoch 16\\Batch 1600\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:02:23] Epoch 16\\Batch 1800\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:04:19] Epoch 16\\Batch 2000\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:06:17] Epoch 16\\Batch 2200\\ Train Loss:4.068\\ Train Accuracy:0.301\n",
      "[2019/03/23 15:08:14] Epoch 16\\Batch 2400\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:10:12] Epoch 16\\Batch 2600\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:12:21] Epoch 16\\Batch 2800\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:14:31] Epoch 16\\Batch 3000\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:16:43] Epoch 16\\Batch 3200\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:18:54] Epoch 16\\Batch 3400\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:21:03] Epoch 16\\Batch 3600\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:23:00] Epoch 16\\Batch 3800\\ Train Loss:4.068\\ Train Accuracy:0.301\n",
      "[2019/03/23 15:25:03] Epoch 16\\Batch 4000\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:27:09] Epoch 16\\Batch 4200\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:29:15] Epoch 16\\Batch 4400\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:31:24] Epoch 16\\Batch 4600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 15:33:33] Epoch 16\\Batch 4800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 15:35:43] Epoch 16\\Batch 5000\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:37:58] Epoch 16\\Batch 5200\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:40:09] Epoch 16\\Batch 5400\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:42:27] Epoch 16\\Batch 5600\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "run model on validation data...\n",
      "[2019/03/23 15:44:25] Epoch 16\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/23 15:46:38] Epoch 17\\Batch 200\\ Train Loss:4.079\\ Train Accuracy:0.298\n",
      "[2019/03/23 15:48:48] Epoch 17\\Batch 400\\ Train Loss:4.075\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:50:58] Epoch 17\\Batch 600\\ Train Loss:4.072\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:53:09] Epoch 17\\Batch 800\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:55:02] Epoch 17\\Batch 1000\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:57:06] Epoch 17\\Batch 1200\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 15:59:11] Epoch 17\\Batch 1400\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:01:17] Epoch 17\\Batch 1600\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:03:21] Epoch 17\\Batch 1800\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:05:26] Epoch 17\\Batch 2000\\ Train Loss:4.068\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:07:36] Epoch 17\\Batch 2200\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:09:46] Epoch 17\\Batch 2400\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:11:55] Epoch 17\\Batch 2600\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:14:05] Epoch 17\\Batch 2800\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:16:14] Epoch 17\\Batch 3000\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:18:25] Epoch 17\\Batch 3200\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:20:34] Epoch 17\\Batch 3400\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:22:41] Epoch 17\\Batch 3600\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:24:44] Epoch 17\\Batch 3800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:26:48] Epoch 17\\Batch 4000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:28:39] Epoch 17\\Batch 4200\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:30:49] Epoch 17\\Batch 4400\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:32:59] Epoch 17\\Batch 4600\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:35:09] Epoch 17\\Batch 4800\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:37:18] Epoch 17\\Batch 5000\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:39:29] Epoch 17\\Batch 5200\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 16:41:38] Epoch 17\\Batch 5400\\ Train Loss:4.066\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:43:34] Epoch 17\\Batch 5600\\ Train Loss:4.066\\ Train Accuracy:0.300\n",
      "run model on validation data...\n",
      "[2019/03/23 16:45:21] Epoch 17\\ Validation Loss:4.199/ Validation Accuracy:0.288\n",
      "[2019/03/23 16:47:18] Epoch 18\\Batch 200\\ Train Loss:4.078\\ Train Accuracy:0.299\n",
      "[2019/03/23 16:49:16] Epoch 18\\Batch 400\\ Train Loss:4.074\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:51:14] Epoch 18\\Batch 600\\ Train Loss:4.071\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:53:11] Epoch 18\\Batch 800\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:55:09] Epoch 18\\Batch 1000\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:57:04] Epoch 18\\Batch 1200\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 16:58:50] Epoch 18\\Batch 1400\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:00:43] Epoch 18\\Batch 1600\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:02:36] Epoch 18\\Batch 1800\\ Train Loss:4.068\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:04:29] Epoch 18\\Batch 2000\\ Train Loss:4.068\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:06:21] Epoch 18\\Batch 2200\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:08:13] Epoch 18\\Batch 2400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:11:56] Epoch 18\\Batch 2800\\ Train Loss:4.066\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:13:48] Epoch 18\\Batch 3000\\ Train Loss:4.066\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:15:39] Epoch 18\\Batch 3200\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:17:31] Epoch 18\\Batch 3400\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:19:24] Epoch 18\\Batch 3600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:21:15] Epoch 18\\Batch 3800\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:23:05] Epoch 18\\Batch 4000\\ Train Loss:4.066\\ Train Accuracy:0.301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/23 17:24:55] Epoch 18\\Batch 4200\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:26:34] Epoch 18\\Batch 4400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:28:25] Epoch 18\\Batch 4600\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:30:16] Epoch 18\\Batch 4800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:32:08] Epoch 18\\Batch 5000\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:33:59] Epoch 18\\Batch 5200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:35:51] Epoch 18\\Batch 5400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:37:41] Epoch 18\\Batch 5600\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/23 17:39:23] Epoch 18\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/23 17:41:14] Epoch 19\\Batch 200\\ Train Loss:4.077\\ Train Accuracy:0.299\n",
      "[2019/03/23 17:43:04] Epoch 19\\Batch 400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:44:54] Epoch 19\\Batch 600\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:46:44] Epoch 19\\Batch 800\\ Train Loss:4.068\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:48:35] Epoch 19\\Batch 1000\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:50:25] Epoch 19\\Batch 1200\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:52:14] Epoch 19\\Batch 1400\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:53:53] Epoch 19\\Batch 1600\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 17:55:43] Epoch 19\\Batch 1800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:57:33] Epoch 19\\Batch 2000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 17:59:25] Epoch 19\\Batch 2200\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:01:20] Epoch 19\\Batch 2400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:03:17] Epoch 19\\Batch 2600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:05:15] Epoch 19\\Batch 2800\\ Train Loss:4.066\\ Train Accuracy:0.300\n",
      "[2019/03/23 18:07:11] Epoch 19\\Batch 3000\\ Train Loss:4.066\\ Train Accuracy:0.300\n",
      "[2019/03/23 18:09:08] Epoch 19\\Batch 3200\\ Train Loss:4.066\\ Train Accuracy:0.300\n",
      "[2019/03/23 18:11:05] Epoch 19\\Batch 3400\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 18:13:02] Epoch 19\\Batch 3600\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:14:58] Epoch 19\\Batch 3800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:16:54] Epoch 19\\Batch 4000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:18:48] Epoch 19\\Batch 4200\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:20:38] Epoch 19\\Batch 4400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:22:16] Epoch 19\\Batch 4600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:24:11] Epoch 19\\Batch 4800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:26:08] Epoch 19\\Batch 5000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:28:03] Epoch 19\\Batch 5200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:29:58] Epoch 19\\Batch 5400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:31:54] Epoch 19\\Batch 5600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/23 18:33:40] Epoch 19\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/23 18:35:35] Epoch 20\\Batch 200\\ Train Loss:4.077\\ Train Accuracy:0.299\n",
      "[2019/03/23 18:37:30] Epoch 20\\Batch 400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/23 18:39:24] Epoch 20\\Batch 600\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 18:41:19] Epoch 20\\Batch 800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:43:14] Epoch 20\\Batch 1000\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 18:45:08] Epoch 20\\Batch 1200\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 18:47:04] Epoch 20\\Batch 1400\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 18:48:58] Epoch 20\\Batch 1600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:50:38] Epoch 20\\Batch 1800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:52:28] Epoch 20\\Batch 2000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:54:18] Epoch 20\\Batch 2200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:56:07] Epoch 20\\Batch 2400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:57:58] Epoch 20\\Batch 2600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 18:59:48] Epoch 20\\Batch 2800\\ Train Loss:4.065\\ Train Accuracy:0.300\n",
      "[2019/03/23 19:01:38] Epoch 20\\Batch 3000\\ Train Loss:4.066\\ Train Accuracy:0.300\n",
      "[2019/03/23 19:03:28] Epoch 20\\Batch 3200\\ Train Loss:4.066\\ Train Accuracy:0.300\n",
      "[2019/03/23 19:05:18] Epoch 20\\Batch 3400\\ Train Loss:4.066\\ Train Accuracy:0.300\n",
      "[2019/03/23 19:07:08] Epoch 20\\Batch 3600\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:08:58] Epoch 20\\Batch 3800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:10:49] Epoch 20\\Batch 4000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:12:40] Epoch 20\\Batch 4200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:14:29] Epoch 20\\Batch 4400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:16:20] Epoch 20\\Batch 4600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:18:00] Epoch 20\\Batch 4800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:19:49] Epoch 20\\Batch 5000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:21:39] Epoch 20\\Batch 5200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:23:28] Epoch 20\\Batch 5400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:25:17] Epoch 20\\Batch 5600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/23 19:27:01] Epoch 20\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/23 19:28:54] Epoch 21\\Batch 200\\ Train Loss:4.077\\ Train Accuracy:0.299\n",
      "[2019/03/23 19:30:49] Epoch 21\\Batch 400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/23 19:32:44] Epoch 21\\Batch 600\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 19:34:37] Epoch 21\\Batch 800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:36:30] Epoch 21\\Batch 1000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:38:23] Epoch 21\\Batch 1200\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:40:15] Epoch 21\\Batch 1400\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 19:42:05] Epoch 21\\Batch 1600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:43:54] Epoch 21\\Batch 1800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:45:31] Epoch 21\\Batch 2000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:47:23] Epoch 21\\Batch 2200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:49:17] Epoch 21\\Batch 2400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:51:11] Epoch 21\\Batch 2600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:53:05] Epoch 21\\Batch 2800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:54:59] Epoch 21\\Batch 3000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:56:51] Epoch 21\\Batch 3200\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 19:58:44] Epoch 21\\Batch 3400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:00:38] Epoch 21\\Batch 3600\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:02:32] Epoch 21\\Batch 3800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:04:26] Epoch 21\\Batch 4000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:06:24] Epoch 21\\Batch 4200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:08:21] Epoch 21\\Batch 4400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:10:18] Epoch 21\\Batch 4600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:12:15] Epoch 21\\Batch 4800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:14:07] Epoch 21\\Batch 5000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:15:54] Epoch 21\\Batch 5200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:17:50] Epoch 21\\Batch 5400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:19:46] Epoch 21\\Batch 5600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/23 20:21:30] Epoch 21\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/23 20:23:22] Epoch 22\\Batch 200\\ Train Loss:4.077\\ Train Accuracy:0.299\n",
      "[2019/03/23 20:25:17] Epoch 22\\Batch 400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/23 20:27:12] Epoch 22\\Batch 600\\ Train Loss:4.070\\ Train Accuracy:0.300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/23 20:29:06] Epoch 22\\Batch 800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:31:04] Epoch 22\\Batch 1000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:33:02] Epoch 22\\Batch 1200\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:35:00] Epoch 22\\Batch 1400\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 20:36:57] Epoch 22\\Batch 1600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:38:53] Epoch 22\\Batch 1800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:40:49] Epoch 22\\Batch 2000\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:42:37] Epoch 22\\Batch 2200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:44:29] Epoch 22\\Batch 2400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:46:25] Epoch 22\\Batch 2600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:48:21] Epoch 22\\Batch 2800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:50:14] Epoch 22\\Batch 3000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:52:11] Epoch 22\\Batch 3200\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:54:08] Epoch 22\\Batch 3400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:56:06] Epoch 22\\Batch 3600\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:58:03] Epoch 22\\Batch 3800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 20:59:58] Epoch 22\\Batch 4000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:01:54] Epoch 22\\Batch 4200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:03:50] Epoch 22\\Batch 4400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:05:46] Epoch 22\\Batch 4600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:07:42] Epoch 22\\Batch 4800\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:09:35] Epoch 22\\Batch 5000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:11:29] Epoch 22\\Batch 5200\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:13:08] Epoch 22\\Batch 5400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:15:04] Epoch 22\\Batch 5600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/23 21:16:50] Epoch 22\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/23 21:18:45] Epoch 23\\Batch 200\\ Train Loss:4.077\\ Train Accuracy:0.299\n",
      "[2019/03/23 21:20:38] Epoch 23\\Batch 400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/23 21:22:33] Epoch 23\\Batch 600\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 21:24:27] Epoch 23\\Batch 800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:26:20] Epoch 23\\Batch 1000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:28:13] Epoch 23\\Batch 1200\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:30:06] Epoch 23\\Batch 1400\\ Train Loss:4.068\\ Train Accuracy:0.300\n",
      "[2019/03/23 21:31:58] Epoch 23\\Batch 1600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:33:52] Epoch 23\\Batch 1800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:35:44] Epoch 23\\Batch 2000\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:37:37] Epoch 23\\Batch 2200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:39:31] Epoch 23\\Batch 2400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:41:13] Epoch 23\\Batch 2600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:43:05] Epoch 23\\Batch 2800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:44:58] Epoch 23\\Batch 3000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:46:52] Epoch 23\\Batch 3200\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:48:46] Epoch 23\\Batch 3400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:50:41] Epoch 23\\Batch 3600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:52:35] Epoch 23\\Batch 3800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:54:27] Epoch 23\\Batch 4000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:56:20] Epoch 23\\Batch 4200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 21:58:13] Epoch 23\\Batch 4400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:00:02] Epoch 23\\Batch 4600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:01:54] Epoch 23\\Batch 4800\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:03:48] Epoch 23\\Batch 5000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:05:41] Epoch 23\\Batch 5200\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:07:35] Epoch 23\\Batch 5400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:09:18] Epoch 23\\Batch 5600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/23 22:10:59] Epoch 23\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/23 22:12:53] Epoch 24\\Batch 200\\ Train Loss:4.076\\ Train Accuracy:0.299\n",
      "[2019/03/23 22:14:46] Epoch 24\\Batch 400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/23 22:16:42] Epoch 24\\Batch 600\\ Train Loss:4.070\\ Train Accuracy:0.300\n",
      "[2019/03/23 22:18:34] Epoch 24\\Batch 800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:20:29] Epoch 24\\Batch 1000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:22:21] Epoch 24\\Batch 1200\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:24:16] Epoch 24\\Batch 1400\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 22:26:10] Epoch 24\\Batch 1600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:28:04] Epoch 24\\Batch 1800\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:29:57] Epoch 24\\Batch 2000\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:31:53] Epoch 24\\Batch 2200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:33:46] Epoch 24\\Batch 2400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:35:39] Epoch 24\\Batch 2600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:37:20] Epoch 24\\Batch 2800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:39:12] Epoch 24\\Batch 3000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:41:05] Epoch 24\\Batch 3200\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:42:56] Epoch 24\\Batch 3400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:44:46] Epoch 24\\Batch 3600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:46:36] Epoch 24\\Batch 3800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:48:26] Epoch 24\\Batch 4000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:50:16] Epoch 24\\Batch 4200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:52:05] Epoch 24\\Batch 4400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:53:55] Epoch 24\\Batch 4600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:55:44] Epoch 24\\Batch 4800\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:57:34] Epoch 24\\Batch 5000\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 22:59:24] Epoch 24\\Batch 5200\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:01:13] Epoch 24\\Batch 5400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:03:02] Epoch 24\\Batch 5600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/23 23:04:43] Epoch 24\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/23 23:06:20] Epoch 25\\Batch 200\\ Train Loss:4.076\\ Train Accuracy:0.299\n",
      "[2019/03/23 23:08:09] Epoch 25\\Batch 400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/23 23:09:59] Epoch 25\\Batch 600\\ Train Loss:4.069\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:11:49] Epoch 25\\Batch 800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:13:38] Epoch 25\\Batch 1000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:15:27] Epoch 25\\Batch 1200\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:17:16] Epoch 25\\Batch 1400\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/23 23:19:05] Epoch 25\\Batch 1600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:20:54] Epoch 25\\Batch 1800\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:22:44] Epoch 25\\Batch 2000\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:24:34] Epoch 25\\Batch 2200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:26:23] Epoch 25\\Batch 2400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:28:12] Epoch 25\\Batch 2600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:30:02] Epoch 25\\Batch 2800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:31:44] Epoch 25\\Batch 3000\\ Train Loss:4.065\\ Train Accuracy:0.301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/23 23:33:28] Epoch 25\\Batch 3200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:35:17] Epoch 25\\Batch 3400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:37:08] Epoch 25\\Batch 3600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:38:55] Epoch 25\\Batch 3800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:40:45] Epoch 25\\Batch 4000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:42:35] Epoch 25\\Batch 4200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:44:25] Epoch 25\\Batch 4400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:46:14] Epoch 25\\Batch 4600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:48:04] Epoch 25\\Batch 4800\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:49:54] Epoch 25\\Batch 5000\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:51:43] Epoch 25\\Batch 5200\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:53:33] Epoch 25\\Batch 5400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/23 23:55:22] Epoch 25\\Batch 5600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/23 23:57:03] Epoch 25\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/23 23:58:53] Epoch 26\\Batch 200\\ Train Loss:4.076\\ Train Accuracy:0.299\n",
      "[2019/03/24 00:00:31] Epoch 26\\Batch 400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/24 00:02:22] Epoch 26\\Batch 600\\ Train Loss:4.069\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:04:12] Epoch 26\\Batch 800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:06:02] Epoch 26\\Batch 1000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:07:51] Epoch 26\\Batch 1200\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:09:39] Epoch 26\\Batch 1400\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/24 00:11:28] Epoch 26\\Batch 1600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:13:17] Epoch 26\\Batch 1800\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:15:07] Epoch 26\\Batch 2000\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:16:57] Epoch 26\\Batch 2200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:18:47] Epoch 26\\Batch 2400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:20:35] Epoch 26\\Batch 2600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:22:25] Epoch 26\\Batch 2800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:24:15] Epoch 26\\Batch 3000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:26:03] Epoch 26\\Batch 3200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:27:42] Epoch 26\\Batch 3400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:29:32] Epoch 26\\Batch 3600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:31:22] Epoch 26\\Batch 3800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:33:12] Epoch 26\\Batch 4000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:35:02] Epoch 26\\Batch 4200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:36:51] Epoch 26\\Batch 4400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:38:41] Epoch 26\\Batch 4600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:40:32] Epoch 26\\Batch 4800\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:42:24] Epoch 26\\Batch 5000\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:44:13] Epoch 26\\Batch 5200\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:46:03] Epoch 26\\Batch 5400\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:47:54] Epoch 26\\Batch 5600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/24 00:49:36] Epoch 26\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/24 00:51:26] Epoch 27\\Batch 200\\ Train Loss:4.076\\ Train Accuracy:0.299\n",
      "[2019/03/24 00:53:16] Epoch 27\\Batch 400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/24 00:54:54] Epoch 27\\Batch 600\\ Train Loss:4.069\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:56:44] Epoch 27\\Batch 800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 00:58:33] Epoch 27\\Batch 1000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:00:23] Epoch 27\\Batch 1200\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:02:13] Epoch 27\\Batch 1400\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/24 01:04:02] Epoch 27\\Batch 1600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:05:51] Epoch 27\\Batch 1800\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:07:40] Epoch 27\\Batch 2000\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:09:30] Epoch 27\\Batch 2200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:11:20] Epoch 27\\Batch 2400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:13:09] Epoch 27\\Batch 2600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:14:59] Epoch 27\\Batch 2800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:16:49] Epoch 27\\Batch 3000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:18:39] Epoch 27\\Batch 3200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:20:29] Epoch 27\\Batch 3400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:22:05] Epoch 27\\Batch 3600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:23:56] Epoch 27\\Batch 3800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:25:46] Epoch 27\\Batch 4000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:27:37] Epoch 27\\Batch 4200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:29:27] Epoch 27\\Batch 4400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:31:15] Epoch 27\\Batch 4600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:33:06] Epoch 27\\Batch 4800\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:34:56] Epoch 27\\Batch 5000\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:36:46] Epoch 27\\Batch 5200\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:38:35] Epoch 27\\Batch 5400\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:40:26] Epoch 27\\Batch 5600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/24 01:42:08] Epoch 27\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/24 01:43:59] Epoch 28\\Batch 200\\ Train Loss:4.076\\ Train Accuracy:0.299\n",
      "[2019/03/24 01:45:49] Epoch 28\\Batch 400\\ Train Loss:4.073\\ Train Accuracy:0.300\n",
      "[2019/03/24 01:47:37] Epoch 28\\Batch 600\\ Train Loss:4.069\\ Train Accuracy:0.300\n",
      "[2019/03/24 01:49:16] Epoch 28\\Batch 800\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:51:03] Epoch 28\\Batch 1000\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:52:52] Epoch 28\\Batch 1200\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:54:41] Epoch 28\\Batch 1400\\ Train Loss:4.067\\ Train Accuracy:0.300\n",
      "[2019/03/24 01:56:31] Epoch 28\\Batch 1600\\ Train Loss:4.067\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:58:16] Epoch 28\\Batch 1800\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/24 01:59:47] Epoch 28\\Batch 2000\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:01:17] Epoch 28\\Batch 2200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:02:48] Epoch 28\\Batch 2400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:04:18] Epoch 28\\Batch 2600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:05:48] Epoch 28\\Batch 2800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:07:18] Epoch 28\\Batch 3000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:08:48] Epoch 28\\Batch 3200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:10:19] Epoch 28\\Batch 3400\\ Train Loss:4.066\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:11:41] Epoch 28\\Batch 3600\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:13:11] Epoch 28\\Batch 3800\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:14:41] Epoch 28\\Batch 4000\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:16:11] Epoch 28\\Batch 4200\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:17:42] Epoch 28\\Batch 4400\\ Train Loss:4.065\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:19:12] Epoch 28\\Batch 4600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:20:43] Epoch 28\\Batch 4800\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:22:15] Epoch 28\\Batch 5000\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:23:46] Epoch 28\\Batch 5200\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "[2019/03/24 02:25:17] Epoch 28\\Batch 5400\\ Train Loss:4.064\\ Train Accuracy:0.301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/24 02:26:48] Epoch 28\\Batch 5600\\ Train Loss:4.064\\ Train Accuracy:0.301\n",
      "run model on validation data...\n",
      "[2019/03/24 02:28:11] Epoch 28\\ Validation Loss:4.199/ Validation Accuracy:0.287\n",
      "[2019/03/24 02:28:13] Validation Loss:4.199\\ Validation Accuracy:0.287\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache files exist, going to load in...\n",
      "loading h5_file...\n",
      "h5_file.keys: KeysView(<HDF5 file \"data.h5\" (mode r)>)\n",
      "loading pickle file\n",
      "cache files load successful!\n",
      "train_X.shape: (2959966, 200)\n",
      "train_y.shape: (2959966,)\n",
      "test_X.shape: (20000, 200)\n",
      "test_y.shape: (20000,)\n",
      "test_X[0]: [ 579  343 1173 1843    5  583  292 1173 1843    5 1180 1299  989   10\n",
      "    2   68  153  168  531  109  260  217  277   81   59   81  116  514\n",
      "    6  221  253  224  154  718  553    4  806  538  732  264   74    6\n",
      "  221  224  154  326   11  167  136    4  257  145   37   74  175  214\n",
      "   11   57  110  221    6  364   89   20 4050 2344    4  257   78    9\n",
      "  991  326  221   89  699  133   11  597  679 1957  824  884  871 1957\n",
      "  824    4  178   87   87   78  196   52  552   69   47   20   12   37\n",
      " 1371   89    6  755  779   81  667  597    4  586  878    6   35   93\n",
      "    7  719  285  937   35  162   13   11    7 1371   89   35    4  201\n",
      "   68   81   97 1533   81  667  597    9  991  326   35  343  704   16\n",
      "    5   99   13    9  991  654  583  292    4   13  221    6  795  230\n",
      "   11   11  350   12  495  235    7  990  625  718  553  297  215  954\n",
      "  549    4   12  165  198   67   93    9  166  110  146    4   81   86\n",
      "   93  141   87 1146  118  224  154   93  147    9   20    4   81  407\n",
      "   92  116  514   12]\n",
      "test_y[0]: 808\n",
      "[2019/03/24 08:31:42] restore from checkpoint\n",
      "INFO:tensorflow:Restoring parameters from testrnn_singlelabel_checkpoint/model.ckpt-28\n",
      "[2019/03/24 08:31:48] Validation Loss:4.141\\ Validation Accuracy:0.294\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
