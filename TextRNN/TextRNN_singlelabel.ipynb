{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义TextRNN结构，使用双向的LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRNN:\n",
    "    def __init__(self, batch_size, num_classes, vocab_size, sentence_len, embed_size, \n",
    "                 learning_rate, decay_steps, decay_rate, is_training):\n",
    "        #1.定义超参数\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sentence_len = sentence_len\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = embed_size #lstm层的维度\n",
    "        self.learning_rate = learning_rate\n",
    "        self.is_training = is_training\n",
    "        self.initializer = tf.random_normal_initializer(stddev=0.1)\n",
    "        \n",
    "        #epoch信息\n",
    "        self.global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "        self.epoch_step = tf.Variable(0, trainable=False, name='epoch_step')\n",
    "        self.epoch_increment = tf.assign(self.epoch_step, tf.add(self.epoch_step, tf.constant(1)))\n",
    "        self.decay_steps, self.decay_rate = decay_steps, decay_rate\n",
    "        \n",
    "        #2.输入\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sentence_len], 'input_x')\n",
    "        self.input_y = tf.placeholder(tf.int32, [None], 'input_y') #单个标签\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name='dropout_keep_prob')\n",
    "        \n",
    "        #3.初始化全连接层参数\n",
    "        self.init_weight()\n",
    "        \n",
    "        #4.网络结构\n",
    "        self.logits = self.inference() #[batch_size, num_classes]\n",
    "        \n",
    "        #5.损失函数\n",
    "        self.loss_val = self.loss()\n",
    "        \n",
    "        #6.优化器\n",
    "        self.train_op = self.train()\n",
    "        \n",
    "        #7.计算acc\n",
    "        self.prediction = tf.argmax(self.logits, axis=1) #[batch_size]\n",
    "        is_right = tf.equal(tf.cast(self.prediction, tf.int32), self.input_y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(is_right, tf.float32))\n",
    "        \n",
    "    def init_weight(self):\n",
    "        self.Embedding = tf.get_variable('Embedding', [self.vocab_size, self.embed_size], dtype=tf.float32)\n",
    "        self.W = tf.get_variable('W', [self.hidden_size * 2, self.num_classes], dtype=tf.float32) #双向LSTM，输出concat，所以此处为2倍\n",
    "        self.b = tf.get_variable('b', [self.num_classes], dtype=tf.float32)\n",
    "        \n",
    "    def inference(self):\n",
    "        # a.embedding\n",
    "        self.sentence_embed = tf.nn.embedding_lookup(self.Embedding, self.input_x) #[batch_size, sentence_len, embed_size]\n",
    "        \n",
    "        # b.bidiretional lstm\n",
    "        self.fw_cell = tf.contrib.rnn.BasicLSTMCell(self.hidden_size) #前向单元\n",
    "        self.bw_cell = tf.contrib.rnn.BasicLSTMCell(self.hidden_size) #后向单元\n",
    "#         if self.dropout_keep_prob is not None:\n",
    "#             self.fw_cell = tf.contrib.rnn.DropoutWrapper(self.fw_cell, output_keep_prob=) \n",
    "                #input_keep_prob是对输入而言，output_keep_prb是对lstm各层而言\n",
    "        outputs, _ = tf.nn.bidirectional_dynamic_rnn(self.fw_cell, self.bw_cell, self.sentence_embed, dtype=tf.float32)\n",
    "        #输入为 [batch_size, sentence_len, embed_size]，输出为大小为2的元组，每个元素为[batch_size, sentence_len, hidden_size]\n",
    "        \n",
    "        # c.concat\n",
    "        fw_output = outputs[0][:,-1,:]\n",
    "        bw_output = outputs[1][:,-1,:] #[batch_size, 1, hidden_size]\n",
    "        final_output = tf.concat([fw_output, bw_output], axis=1) #[batch_size, 1, hidden_size*2]\n",
    "        final_output = tf.reshape(final_output, [-1, self.hidden_size*2]) #[batch_size, hidden_size * 2]\n",
    "        \n",
    "        # d.full_connection\n",
    "        logits = tf.matmul(final_output, self.W) + self.b #[batch_size, num_classes]\n",
    "        return logits\n",
    "    \n",
    "    def loss(self, l2_lambda=0.0001):\n",
    "        loss1 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.input_y, logits=self.logits)\n",
    "        #先将label转化为one-hot形式，再对logits计算softmax，最后计算交叉熵\n",
    "        loss1 = tf.reduce_mean(loss1)\n",
    "        loss2 = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()]) * l2_lambda\n",
    "        return loss1 + loss2\n",
    "    \n",
    "    def train(self):\n",
    "        learning_rate = tf.train.exponential_decay(self.learning_rate, self.global_step, self.decay_steps, self.decay_rate, staircase=True)\n",
    "        train_op = tf.contrib.layers.optimize_loss(self.loss_val, self.global_step, learning_rate, optimizer='Adam')\n",
    "        return train_op\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    num_classes=19\n",
    "    learning_rate=0.01\n",
    "    batch_size=15\n",
    "    decay_step=1000\n",
    "    decay_rate=0.9\n",
    "    sequence_length=5\n",
    "    vocab_size=10000\n",
    "    embed_size=100\n",
    "    is_training=True\n",
    "    dropout_keep_prob=0.5\n",
    "    \n",
    "    model = TextRNN(batch_size, num_classes, vocab_size, sequence_length, embed_size, \n",
    "                     learning_rate, decay_step, decay_rate, True)\n",
    "    print(tf.trainable_variables())\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        input_x = np.random.randint(0,100,size=(batch_size, sequence_length),dtype=np.int32)\n",
    "        input_y = np.random.randint(0, 19,size=(batch_size), dtype=np.int32)\n",
    "        for i in range(20):\n",
    "            #input_x = np.zeros((batch_size, sequence_length), dtype=np.int32)\n",
    "            #input_y = np.array([1,0,1,1,1,2,1,1], dtype=np.int32)\n",
    "            loss, acc, predict, _ = sess.run([model.loss_val, model.accuracy, model.prediction, model.train_op],\n",
    "                                            feed_dict={model.input_x: input_x, model.input_y: input_y,\n",
    "                                                       model.dropout_keep_prob: dropout_keep_prob})\n",
    "            print('loss:',loss, 'acc:', acc, 'label:', input_y, 'predict:', predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Embedding:0' shape=(10000, 100) dtype=float32_ref>, <tf.Variable 'W:0' shape=(200, 19) dtype=float32_ref>, <tf.Variable 'b:0' shape=(19,) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/fw/basic_lstm_cell/kernel:0' shape=(200, 400) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/fw/basic_lstm_cell/bias:0' shape=(400,) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/bw/basic_lstm_cell/kernel:0' shape=(200, 400) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/bw/basic_lstm_cell/bias:0' shape=(400,) dtype=float32_ref>]\n",
      "loss: 3.020527 acc: 0.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "loss: 2.9279802 acc: 0.2 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 2 13 10  2  2  2 10  2  2  2  2  2  2  2  2]\n",
      "loss: 2.7922528 acc: 0.46666667 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [10 13 10 10 10 10 10 10 10 13 13 11 14 14  8]\n",
      "loss: 2.5618093 acc: 0.46666667 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [10 13 10 14 10 14 10 10 10 14 14 11 14 14  8]\n",
      "loss: 2.1775455 acc: 0.6666667 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [14 13 10 14  3  3 10 12 10 12 14 11 14 14 14]\n",
      "loss: 1.6675309 acc: 0.6 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 3 14 10 14  3  3 10 12 10 12 14 11 14 14 14]\n",
      "loss: 1.291603 acc: 0.6 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 3  3 10 14  3  3 10 12 10 12 14 11 14 14 14]\n",
      "loss: 0.8179696 acc: 0.8666667 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10 14  3  3 10 12 10 12  9 11 14 14  8]\n",
      "loss: 0.4429076 acc: 0.8666667 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10 14  3  3 10 12 10 12  9 11 14 14  8]\n",
      "loss: 0.24631916 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n",
      "loss: 0.14331403 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n",
      "loss: 0.08357559 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n",
      "loss: 0.061649658 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n",
      "loss: 0.05574103 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n",
      "loss: 0.054246664 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n",
      "loss: 0.055098224 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n",
      "loss: 0.05678064 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n",
      "loss: 0.058644738 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n",
      "loss: 0.060476474 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n",
      "loss: 0.062185515 acc: 1.0 label: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8] predict: [ 7 13 10  0  3  3 10 12  6 12  9 11 14 14  8]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# from tflearn.data_utils import to_categorical, pad_sequences\n",
    "import os\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#定义超参数\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('batch_size', 512, 'batch_size')\n",
    "tf.app.flags.DEFINE_integer('num_classes', 1999, 'num_classes')\n",
    "tf.app.flags.DEFINE_integer('sentence_len', 100, 'length of each sentence')\n",
    "tf.app.flags.DEFINE_integer('embed_size', 100, 'embedding size')\n",
    "tf.app.flags.DEFINE_float('learning_rate', 0.01, '')\n",
    "tf.app.flags.DEFINE_float('decay_rate', 0.8, '')\n",
    "tf.app.flags.DEFINE_integer('decay_steps', 3000, 'number of steps before decay learning rate')\n",
    "tf.app.flags.DEFINE_bool('is_training', True, '')\n",
    "\n",
    "tf.app.flags.DEFINE_integer('num_epoch', 20, 'number of epoch')\n",
    "\n",
    "tf.app.flags.DEFINE_string(\"ckpt_dir\",\"testrnn_singlelabel_checkpoint_noembed/\",\"checkpoint location for the model\")\n",
    "tf.app.flags.DEFINE_string(\"cache_path\",\"textrnn_singlelabel_checkpoint_noembed/data_cache.pik\",\"data chche for the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def log(str):\n",
    "    t = time.localtime()\n",
    "    print(\"[%4d/%02d/%02d %02d:%02d:%02d]\"%(t.tm_year, t.tm_mon, t.tm_mday, t.tm_hour, t.tm_min, t.tm_sec), end=' ')\n",
    "    print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    #1.加载数据\n",
    "    base_path = '../zhihu_data/'\n",
    "    cache_file_h5py = base_path + 'data.h5'\n",
    "    cache_file_pickle = base_path + 'vocab_label.pik'\n",
    "    word2index,label2index,train_X,train_y,vaild_X,valid_y,test_X,test_y,embedding_final = load_data(cache_file_h5py, cache_file_pickle)\n",
    "    vocab_size = len(word2index)\n",
    "    \n",
    "    print(\"train_X.shape:\", np.array(train_X).shape)\n",
    "    print(\"train_y.shape:\", np.array(train_y).shape)\n",
    "    print(\"test_X.shape:\", np.array(test_X).shape)  # 每个list代表一句话\n",
    "    print(\"test_y.shape:\", np.array(test_y).shape)  \n",
    "    print(\"test_X[0]:\", test_X[0])  \n",
    "    print(\"test_y[0]:\", test_y[0]) \n",
    "    \n",
    "    #2.创建session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        model = TextRNN(FLAGS.batch_size, FLAGS.num_classes, vocab_size, FLAGS.sentence_len,FLAGS.embed_size, \n",
    "                        FLAGS.learning_rate, FLAGS.decay_steps, FLAGS.decay_rate, FLAGS.is_training)\n",
    "        saver = tf.train.Saver()\n",
    "        batch_size = FLAGS.batch_size\n",
    "        CONTINUE_TRAIN = False\n",
    "        if os.path.exists(FLAGS.ckpt_dir + 'checkpoint'):\n",
    "            log(\"restore from checkpoint\")\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(FLAGS.ckpt_dir))\n",
    "            if CONTINUE_TRAIN: log(\"continue training...\")\n",
    "        else:\n",
    "            log('init variables')\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "#             #是否使用embedding\n",
    "#             print('assign pre-trained embedding')\n",
    "#             embedding_assign = tf.assign(model.Embedding, tf.constant(np.array(embedding_final))) #为model.Embedding赋值\n",
    "#             sess.run(embedding_assign)\n",
    "        if not os.path.exists(FLAGS.ckpt_dir + 'checkpoint') or CONTINUE_TRAIN:\n",
    "            num_of_data = len(train_y)\n",
    "            for _ in range(FLAGS.num_epoch):\n",
    "                epoch = sess.run(model.epoch_step)\n",
    "                loss, acc, counter = 0., 0., 0.\n",
    "                for start, end in zip(range(0, num_of_data, batch_size), range(batch_size, num_of_data, batch_size)):\n",
    "                    loss_tmp, acc_tmp, _ = sess.run([model.loss_val, model.accuracy, model.train_op], \n",
    "                                                    feed_dict={model.input_x: train_X[start:end,:100], model.input_y: train_y[start:end],\n",
    "                                                               model.dropout_keep_prob: 1})\n",
    "                    loss, acc, counter = loss + loss_tmp, acc + acc_tmp, counter + 1\n",
    "                    if counter % 200 == 0:\n",
    "                        log(\"Epoch %d\\Batch %d\\ Train Loss:%.3f\\ Train Accuracy:%.3f\"%(epoch, counter, loss/float(counter), acc/float(counter)))\n",
    "\n",
    "                print('run model on validation data...')\n",
    "                loss_valid, acc_valid = do_eval(sess, model, vaild_X, valid_y, batch_size)\n",
    "                log(\"Epoch %d\\ Validation Loss:%.3f/ Validation Accuracy:%.3f\"%(epoch, loss_valid, acc_valid))\n",
    "                #save the checkpoint\n",
    "                save_path = FLAGS.ckpt_dir + 'model.ckpt'\n",
    "                saver.save(sess, save_path, global_step=model.epoch_step)\n",
    "                sess.run(model.epoch_increment)\n",
    "            loss_valid, acc_valid = do_eval(sess, model, vaild_X, valid_y, batch_size)\n",
    "            log(\"Validation Loss:%.3f\\ Validation Accuracy:%.3f\"%(loss_valid, acc_valid))\n",
    "        loss_valid, acc_valid = do_eval(sess, model, vaild_X, valid_y, batch_size)\n",
    "        log(\"Validation Loss:%.3f\\ Validation Accuracy:%.3f\"%(loss_valid, acc_valid))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(h5_file_path, pik_file_path):\n",
    "    if not os.path.exists(h5_file_path) or not os.path.exists(pik_file_path):\n",
    "        raise RuntimeError('No such file!!')\n",
    "\n",
    "    print('cache files exist, going to load in...')\n",
    "    print('loading h5_file...')\n",
    "    h5_file = h5py.File(h5_file_path, 'r')\n",
    "    print('h5_file.keys:', h5_file.keys())\n",
    "    train_X, train_y = h5_file['train_X'], h5_file['train_Y']\n",
    "    vaild_X, valid_y = h5_file['vaild_X'], h5_file['valid_Y']\n",
    "    test_X,  test_y  = h5_file['test_X'],  h5_file['test_Y']\n",
    "    embedding_final = h5_file['embedding']\n",
    "\n",
    "    print('loading pickle file')\n",
    "    word2index, label2index = None, None\n",
    "    with open(pik_file_path, 'rb') as pkl:\n",
    "        word2index,label2index = pickle.load(pkl)\n",
    "    print('cache files load successful!')\n",
    "    return word2index,label2index,train_X,train_y,vaild_X,valid_y,test_X,test_y, embedding_final\n",
    "\n",
    "def do_eval(sess, model, test_X, test_y, batch_size):\n",
    "#     test_X, test_y = test_X[:5000], test_y[:5000]\n",
    "    num_of_data = len(test_y)\n",
    "    loss, acc, counter = 0.0, 0.0, 0\n",
    "    for start, end in zip(range(0, num_of_data, batch_size), range(batch_size, num_of_data, batch_size)):\n",
    "        l,a = sess.run([model.loss_val, model.accuracy], \n",
    "                        feed_dict={model.input_x: test_X[start:end,:100], model.input_y: test_y[start:end], model.dropout_keep_prob:1.0})\n",
    "        loss, acc, counter = loss+l, acc+a, counter+1\n",
    "    return loss/float(counter), acc/float(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache files exist, going to load in...\n",
      "loading h5_file...\n",
      "h5_file.keys: KeysView(<HDF5 file \"data.h5\" (mode r)>)\n",
      "loading pickle file\n",
      "cache files load successful!\n",
      "train_X.shape: (2959966, 200)\n",
      "train_y.shape: (2959966,)\n",
      "test_X.shape: (20000, 200)\n",
      "test_y.shape: (20000,)\n",
      "test_X[0]: [ 579  343 1173 1843    5  583  292 1173 1843    5 1180 1299  989   10\n",
      "    2   68  153  168  531  109  260  217  277   81   59   81  116  514\n",
      "    6  221  253  224  154  718  553    4  806  538  732  264   74    6\n",
      "  221  224  154  326   11  167  136    4  257  145   37   74  175  214\n",
      "   11   57  110  221    6  364   89   20 4050 2344    4  257   78    9\n",
      "  991  326  221   89  699  133   11  597  679 1957  824  884  871 1957\n",
      "  824    4  178   87   87   78  196   52  552   69   47   20   12   37\n",
      " 1371   89    6  755  779   81  667  597    4  586  878    6   35   93\n",
      "    7  719  285  937   35  162   13   11    7 1371   89   35    4  201\n",
      "   68   81   97 1533   81  667  597    9  991  326   35  343  704   16\n",
      "    5   99   13    9  991  654  583  292    4   13  221    6  795  230\n",
      "   11   11  350   12  495  235    7  990  625  718  553  297  215  954\n",
      "  549    4   12  165  198   67   93    9  166  110  146    4   81   86\n",
      "   93  141   87 1146  118  224  154   93  147    9   20    4   81  407\n",
      "   92  116  514   12]\n",
      "test_y[0]: 808\n",
      "[2019/03/23 08:30:21] restore from checkpoint\n",
      "INFO:tensorflow:Restoring parameters from testrnn_singlelabel_checkpoint_noembed/model.ckpt-9\n",
      "[2019/03/23 08:30:21] continue training...\n",
      "[2019/03/23 08:32:03] Epoch 9\\Batch 200\\ Train Loss:4.210\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:33:49] Epoch 9\\Batch 400\\ Train Loss:4.207\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:35:35] Epoch 9\\Batch 600\\ Train Loss:4.201\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:37:21] Epoch 9\\Batch 800\\ Train Loss:4.200\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:39:07] Epoch 9\\Batch 1000\\ Train Loss:4.201\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:40:54] Epoch 9\\Batch 1200\\ Train Loss:4.200\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:42:40] Epoch 9\\Batch 1400\\ Train Loss:4.199\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:44:26] Epoch 9\\Batch 1600\\ Train Loss:4.199\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:46:13] Epoch 9\\Batch 1800\\ Train Loss:4.199\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:48:00] Epoch 9\\Batch 2000\\ Train Loss:4.199\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:49:46] Epoch 9\\Batch 2200\\ Train Loss:4.197\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:51:33] Epoch 9\\Batch 2400\\ Train Loss:4.198\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:53:14] Epoch 9\\Batch 2600\\ Train Loss:4.197\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:54:55] Epoch 9\\Batch 2800\\ Train Loss:4.197\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:56:42] Epoch 9\\Batch 3000\\ Train Loss:4.197\\ Train Accuracy:0.286\n",
      "[2019/03/23 08:58:29] Epoch 9\\Batch 3200\\ Train Loss:4.197\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:00:14] Epoch 9\\Batch 3400\\ Train Loss:4.197\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:02:00] Epoch 9\\Batch 3600\\ Train Loss:4.197\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:03:47] Epoch 9\\Batch 3800\\ Train Loss:4.196\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:05:33] Epoch 9\\Batch 4000\\ Train Loss:4.195\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:07:20] Epoch 9\\Batch 4200\\ Train Loss:4.195\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:09:06] Epoch 9\\Batch 4400\\ Train Loss:4.195\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:10:53] Epoch 9\\Batch 4600\\ Train Loss:4.194\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:12:39] Epoch 9\\Batch 4800\\ Train Loss:4.194\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:14:27] Epoch 9\\Batch 5000\\ Train Loss:4.194\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:16:15] Epoch 9\\Batch 5200\\ Train Loss:4.194\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:18:07] Epoch 9\\Batch 5400\\ Train Loss:4.194\\ Train Accuracy:0.286\n",
      "[2019/03/23 09:19:54] Epoch 9\\Batch 5600\\ Train Loss:4.194\\ Train Accuracy:0.286\n",
      "run model on validation data...\n",
      "[2019/03/23 09:21:29] Epoch 9\\ Validation Loss:4.282/ Validation Accuracy:0.273\n",
      "[2019/03/23 09:23:19] Epoch 10\\Batch 200\\ Train Loss:4.195\\ Train Accuracy:0.287\n",
      "[2019/03/23 09:25:10] Epoch 10\\Batch 400\\ Train Loss:4.192\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:27:02] Epoch 10\\Batch 600\\ Train Loss:4.186\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:28:54] Epoch 10\\Batch 800\\ Train Loss:4.185\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:30:41] Epoch 10\\Batch 1000\\ Train Loss:4.186\\ Train Accuracy:0.287\n",
      "[2019/03/23 09:32:28] Epoch 10\\Batch 1200\\ Train Loss:4.185\\ Train Accuracy:0.287\n",
      "[2019/03/23 09:34:14] Epoch 10\\Batch 1400\\ Train Loss:4.184\\ Train Accuracy:0.287\n",
      "[2019/03/23 09:36:00] Epoch 10\\Batch 1600\\ Train Loss:4.184\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:37:46] Epoch 10\\Batch 1800\\ Train Loss:4.184\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:39:33] Epoch 10\\Batch 2000\\ Train Loss:4.183\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:41:17] Epoch 10\\Batch 2200\\ Train Loss:4.182\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:43:06] Epoch 10\\Batch 2400\\ Train Loss:4.182\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:44:52] Epoch 10\\Batch 2600\\ Train Loss:4.182\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:46:37] Epoch 10\\Batch 2800\\ Train Loss:4.182\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:48:20] Epoch 10\\Batch 3000\\ Train Loss:4.183\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:50:00] Epoch 10\\Batch 3200\\ Train Loss:4.183\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:51:46] Epoch 10\\Batch 3400\\ Train Loss:4.183\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:53:33] Epoch 10\\Batch 3600\\ Train Loss:4.182\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:55:18] Epoch 10\\Batch 3800\\ Train Loss:4.181\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:57:04] Epoch 10\\Batch 4000\\ Train Loss:4.181\\ Train Accuracy:0.288\n",
      "[2019/03/23 09:58:51] Epoch 10\\Batch 4200\\ Train Loss:4.181\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:00:38] Epoch 10\\Batch 4400\\ Train Loss:4.181\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:02:24] Epoch 10\\Batch 4600\\ Train Loss:4.180\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:04:12] Epoch 10\\Batch 4800\\ Train Loss:4.180\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:05:59] Epoch 10\\Batch 5000\\ Train Loss:4.180\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:07:45] Epoch 10\\Batch 5200\\ Train Loss:4.180\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:09:30] Epoch 10\\Batch 5400\\ Train Loss:4.180\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:11:19] Epoch 10\\Batch 5600\\ Train Loss:4.180\\ Train Accuracy:0.288\n",
      "run model on validation data...\n",
      "[2019/03/23 10:12:58] Epoch 10\\ Validation Loss:4.277/ Validation Accuracy:0.274\n",
      "[2019/03/23 10:14:41] Epoch 11\\Batch 200\\ Train Loss:4.185\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:16:18] Epoch 11\\Batch 400\\ Train Loss:4.182\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:18:05] Epoch 11\\Batch 600\\ Train Loss:4.176\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:19:51] Epoch 11\\Batch 800\\ Train Loss:4.175\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:21:38] Epoch 11\\Batch 1000\\ Train Loss:4.176\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:23:24] Epoch 11\\Batch 1200\\ Train Loss:4.175\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:25:10] Epoch 11\\Batch 1400\\ Train Loss:4.174\\ Train Accuracy:0.288\n",
      "[2019/03/23 10:26:56] Epoch 11\\Batch 1600\\ Train Loss:4.173\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:28:45] Epoch 11\\Batch 1800\\ Train Loss:4.173\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:30:31] Epoch 11\\Batch 2000\\ Train Loss:4.173\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:32:18] Epoch 11\\Batch 2200\\ Train Loss:4.171\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:34:05] Epoch 11\\Batch 2400\\ Train Loss:4.172\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:35:52] Epoch 11\\Batch 2600\\ Train Loss:4.172\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:37:37] Epoch 11\\Batch 2800\\ Train Loss:4.172\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:39:23] Epoch 11\\Batch 3000\\ Train Loss:4.173\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:41:11] Epoch 11\\Batch 3200\\ Train Loss:4.173\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:42:53] Epoch 11\\Batch 3400\\ Train Loss:4.173\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:44:31] Epoch 11\\Batch 3600\\ Train Loss:4.172\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:46:19] Epoch 11\\Batch 3800\\ Train Loss:4.172\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:48:06] Epoch 11\\Batch 4000\\ Train Loss:4.171\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:49:53] Epoch 11\\Batch 4200\\ Train Loss:4.172\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:51:39] Epoch 11\\Batch 4400\\ Train Loss:4.171\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:53:26] Epoch 11\\Batch 4600\\ Train Loss:4.171\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:55:11] Epoch 11\\Batch 4800\\ Train Loss:4.170\\ Train Accuracy:0.289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/23 10:56:58] Epoch 11\\Batch 5000\\ Train Loss:4.170\\ Train Accuracy:0.289\n",
      "[2019/03/23 10:58:45] Epoch 11\\Batch 5200\\ Train Loss:4.170\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:00:33] Epoch 11\\Batch 5400\\ Train Loss:4.171\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:02:20] Epoch 11\\Batch 5600\\ Train Loss:4.170\\ Train Accuracy:0.289\n",
      "run model on validation data...\n",
      "[2019/03/23 11:03:58] Epoch 11\\ Validation Loss:4.274/ Validation Accuracy:0.274\n",
      "[2019/03/23 11:05:46] Epoch 12\\Batch 200\\ Train Loss:4.178\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:07:34] Epoch 12\\Batch 400\\ Train Loss:4.175\\ Train Accuracy:0.290\n",
      "[2019/03/23 11:09:18] Epoch 12\\Batch 600\\ Train Loss:4.169\\ Train Accuracy:0.290\n",
      "[2019/03/23 11:10:56] Epoch 12\\Batch 800\\ Train Loss:4.168\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:12:43] Epoch 12\\Batch 1000\\ Train Loss:4.169\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:14:29] Epoch 12\\Batch 1200\\ Train Loss:4.168\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:16:15] Epoch 12\\Batch 1400\\ Train Loss:4.167\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:18:00] Epoch 12\\Batch 1600\\ Train Loss:4.166\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:19:46] Epoch 12\\Batch 1800\\ Train Loss:4.166\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:21:32] Epoch 12\\Batch 2000\\ Train Loss:4.166\\ Train Accuracy:0.290\n",
      "[2019/03/23 11:23:18] Epoch 12\\Batch 2200\\ Train Loss:4.164\\ Train Accuracy:0.290\n",
      "[2019/03/23 11:25:05] Epoch 12\\Batch 2400\\ Train Loss:4.164\\ Train Accuracy:0.290\n",
      "[2019/03/23 11:26:52] Epoch 12\\Batch 2600\\ Train Loss:4.164\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:28:39] Epoch 12\\Batch 2800\\ Train Loss:4.165\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:30:25] Epoch 12\\Batch 3000\\ Train Loss:4.165\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:32:10] Epoch 12\\Batch 3200\\ Train Loss:4.166\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:33:54] Epoch 12\\Batch 3400\\ Train Loss:4.166\\ Train Accuracy:0.290\n",
      "[2019/03/23 11:35:40] Epoch 12\\Batch 3600\\ Train Loss:4.166\\ Train Accuracy:0.290\n",
      "[2019/03/23 11:37:25] Epoch 12\\Batch 3800\\ Train Loss:4.165\\ Train Accuracy:0.290\n",
      "[2019/03/23 11:39:01] Epoch 12\\Batch 4000\\ Train Loss:4.165\\ Train Accuracy:0.290\n",
      "[2019/03/23 11:40:47] Epoch 12\\Batch 4200\\ Train Loss:4.165\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:42:32] Epoch 12\\Batch 4400\\ Train Loss:4.165\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:44:21] Epoch 12\\Batch 4600\\ Train Loss:4.164\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:46:10] Epoch 12\\Batch 4800\\ Train Loss:4.164\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:47:56] Epoch 12\\Batch 5000\\ Train Loss:4.164\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:49:43] Epoch 12\\Batch 5200\\ Train Loss:4.164\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:51:29] Epoch 12\\Batch 5400\\ Train Loss:4.164\\ Train Accuracy:0.289\n",
      "[2019/03/23 11:53:17] Epoch 12\\Batch 5600\\ Train Loss:4.164\\ Train Accuracy:0.289\n",
      "run model on validation data...\n",
      "[2019/03/23 11:54:57] Epoch 12\\ Validation Loss:4.272/ Validation Accuracy:0.274\n",
      "[2019/03/23 11:56:44] Epoch 13\\Batch 200\\ Train Loss:4.173\\ Train Accuracy:0.290\n",
      "[2019/03/23 11:58:32] Epoch 13\\Batch 400\\ Train Loss:4.170\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:00:18] Epoch 13\\Batch 600\\ Train Loss:4.164\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:02:04] Epoch 13\\Batch 800\\ Train Loss:4.163\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:03:50] Epoch 13\\Batch 1000\\ Train Loss:4.164\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:05:25] Epoch 13\\Batch 1200\\ Train Loss:4.163\\ Train Accuracy:0.289\n",
      "[2019/03/23 12:07:11] Epoch 13\\Batch 1400\\ Train Loss:4.162\\ Train Accuracy:0.289\n",
      "[2019/03/23 12:08:59] Epoch 13\\Batch 1600\\ Train Loss:4.162\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:10:45] Epoch 13\\Batch 1800\\ Train Loss:4.162\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:12:32] Epoch 13\\Batch 2000\\ Train Loss:4.161\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:14:20] Epoch 13\\Batch 2200\\ Train Loss:4.160\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:16:07] Epoch 13\\Batch 2400\\ Train Loss:4.160\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:17:57] Epoch 13\\Batch 2600\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:19:47] Epoch 13\\Batch 2800\\ Train Loss:4.160\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:21:38] Epoch 13\\Batch 3000\\ Train Loss:4.161\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:23:28] Epoch 13\\Batch 3200\\ Train Loss:4.161\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:25:18] Epoch 13\\Batch 3400\\ Train Loss:4.161\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:27:08] Epoch 13\\Batch 3600\\ Train Loss:4.161\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:29:00] Epoch 13\\Batch 3800\\ Train Loss:4.160\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:30:49] Epoch 13\\Batch 4000\\ Train Loss:4.160\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:32:33] Epoch 13\\Batch 4200\\ Train Loss:4.160\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:34:10] Epoch 13\\Batch 4400\\ Train Loss:4.160\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:35:55] Epoch 13\\Batch 4600\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:37:41] Epoch 13\\Batch 4800\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:39:28] Epoch 13\\Batch 5000\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:41:17] Epoch 13\\Batch 5200\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:43:04] Epoch 13\\Batch 5400\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:44:50] Epoch 13\\Batch 5600\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "run model on validation data...\n",
      "[2019/03/23 12:46:30] Epoch 13\\ Validation Loss:4.271/ Validation Accuracy:0.273\n",
      "[2019/03/23 12:48:16] Epoch 14\\Batch 200\\ Train Loss:4.169\\ Train Accuracy:0.291\n",
      "[2019/03/23 12:50:02] Epoch 14\\Batch 400\\ Train Loss:4.167\\ Train Accuracy:0.291\n",
      "[2019/03/23 12:51:49] Epoch 14\\Batch 600\\ Train Loss:4.161\\ Train Accuracy:0.291\n",
      "[2019/03/23 12:53:35] Epoch 14\\Batch 800\\ Train Loss:4.160\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:55:22] Epoch 14\\Batch 1000\\ Train Loss:4.161\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:57:09] Epoch 14\\Batch 1200\\ Train Loss:4.160\\ Train Accuracy:0.290\n",
      "[2019/03/23 12:58:56] Epoch 14\\Batch 1400\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:00:31] Epoch 14\\Batch 1600\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:02:20] Epoch 14\\Batch 1800\\ Train Loss:4.159\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:04:12] Epoch 14\\Batch 2000\\ Train Loss:4.158\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:06:04] Epoch 14\\Batch 2200\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:07:56] Epoch 14\\Batch 2400\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:09:46] Epoch 14\\Batch 2600\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:11:38] Epoch 14\\Batch 2800\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:13:29] Epoch 14\\Batch 3000\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:15:16] Epoch 14\\Batch 3200\\ Train Loss:4.158\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:17:02] Epoch 14\\Batch 3400\\ Train Loss:4.158\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:18:49] Epoch 14\\Batch 3600\\ Train Loss:4.158\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:20:35] Epoch 14\\Batch 3800\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:22:22] Epoch 14\\Batch 4000\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:24:08] Epoch 14\\Batch 4200\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:25:54] Epoch 14\\Batch 4400\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:27:38] Epoch 14\\Batch 4600\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:29:14] Epoch 14\\Batch 4800\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:31:03] Epoch 14\\Batch 5000\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:32:49] Epoch 14\\Batch 5200\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:34:36] Epoch 14\\Batch 5400\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:36:22] Epoch 14\\Batch 5600\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "run model on validation data...\n",
      "[2019/03/23 13:38:01] Epoch 14\\ Validation Loss:4.270/ Validation Accuracy:0.273\n",
      "[2019/03/23 13:39:50] Epoch 15\\Batch 200\\ Train Loss:4.166\\ Train Accuracy:0.291\n",
      "[2019/03/23 13:41:41] Epoch 15\\Batch 400\\ Train Loss:4.164\\ Train Accuracy:0.291\n",
      "[2019/03/23 13:43:32] Epoch 15\\Batch 600\\ Train Loss:4.158\\ Train Accuracy:0.291\n",
      "[2019/03/23 13:45:23] Epoch 15\\Batch 800\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:47:15] Epoch 15\\Batch 1000\\ Train Loss:4.158\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:49:06] Epoch 15\\Batch 1200\\ Train Loss:4.158\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:50:58] Epoch 15\\Batch 1400\\ Train Loss:4.157\\ Train Accuracy:0.290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/23 13:52:48] Epoch 15\\Batch 1600\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:54:39] Epoch 15\\Batch 1800\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:56:15] Epoch 15\\Batch 2000\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 13:58:07] Epoch 15\\Batch 2200\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 13:59:59] Epoch 15\\Batch 2400\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:01:51] Epoch 15\\Batch 2600\\ Train Loss:4.154\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:03:42] Epoch 15\\Batch 2800\\ Train Loss:4.154\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:05:33] Epoch 15\\Batch 3000\\ Train Loss:4.155\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:07:27] Epoch 15\\Batch 3200\\ Train Loss:4.155\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:09:19] Epoch 15\\Batch 3400\\ Train Loss:4.156\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:11:07] Epoch 15\\Batch 3600\\ Train Loss:4.155\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:12:54] Epoch 15\\Batch 3800\\ Train Loss:4.155\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:14:43] Epoch 15\\Batch 4000\\ Train Loss:4.155\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:16:33] Epoch 15\\Batch 4200\\ Train Loss:4.155\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:18:25] Epoch 15\\Batch 4400\\ Train Loss:4.155\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:20:16] Epoch 15\\Batch 4600\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:22:05] Epoch 15\\Batch 4800\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:23:56] Epoch 15\\Batch 5000\\ Train Loss:4.154\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:25:34] Epoch 15\\Batch 5200\\ Train Loss:4.154\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:27:25] Epoch 15\\Batch 5400\\ Train Loss:4.154\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:29:11] Epoch 15\\Batch 5600\\ Train Loss:4.154\\ Train Accuracy:0.290\n",
      "run model on validation data...\n",
      "[2019/03/23 14:30:48] Epoch 15\\ Validation Loss:4.269/ Validation Accuracy:0.273\n",
      "[2019/03/23 14:32:35] Epoch 16\\Batch 200\\ Train Loss:4.164\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:34:22] Epoch 16\\Batch 400\\ Train Loss:4.162\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:36:10] Epoch 16\\Batch 600\\ Train Loss:4.156\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:38:01] Epoch 16\\Batch 800\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:39:51] Epoch 16\\Batch 1000\\ Train Loss:4.157\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:41:44] Epoch 16\\Batch 1200\\ Train Loss:4.156\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:43:34] Epoch 16\\Batch 1400\\ Train Loss:4.155\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:45:24] Epoch 16\\Batch 1600\\ Train Loss:4.155\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:47:14] Epoch 16\\Batch 1800\\ Train Loss:4.155\\ Train Accuracy:0.290\n",
      "[2019/03/23 14:49:04] Epoch 16\\Batch 2000\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:50:52] Epoch 16\\Batch 2200\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:52:27] Epoch 16\\Batch 2400\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:54:13] Epoch 16\\Batch 2600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:56:01] Epoch 16\\Batch 2800\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:57:49] Epoch 16\\Batch 3000\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 14:59:38] Epoch 16\\Batch 3200\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:01:31] Epoch 16\\Batch 3400\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:03:24] Epoch 16\\Batch 3600\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:05:19] Epoch 16\\Batch 3800\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:07:13] Epoch 16\\Batch 4000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:09:06] Epoch 16\\Batch 4200\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:11:04] Epoch 16\\Batch 4400\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:13:03] Epoch 16\\Batch 4600\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:15:01] Epoch 16\\Batch 4800\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:16:57] Epoch 16\\Batch 5000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:18:57] Epoch 16\\Batch 5200\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:20:52] Epoch 16\\Batch 5400\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:22:44] Epoch 16\\Batch 5600\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/23 15:24:24] Epoch 16\\ Validation Loss:4.269/ Validation Accuracy:0.273\n",
      "[2019/03/23 15:26:15] Epoch 17\\Batch 200\\ Train Loss:4.163\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:28:08] Epoch 17\\Batch 400\\ Train Loss:4.160\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:30:02] Epoch 17\\Batch 600\\ Train Loss:4.155\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:31:59] Epoch 17\\Batch 800\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:33:53] Epoch 17\\Batch 1000\\ Train Loss:4.155\\ Train Accuracy:0.290\n",
      "[2019/03/23 15:35:47] Epoch 17\\Batch 1200\\ Train Loss:4.155\\ Train Accuracy:0.290\n",
      "[2019/03/23 15:37:45] Epoch 17\\Batch 1400\\ Train Loss:4.154\\ Train Accuracy:0.290\n",
      "[2019/03/23 15:39:51] Epoch 17\\Batch 1600\\ Train Loss:4.154\\ Train Accuracy:0.290\n",
      "[2019/03/23 15:42:15] Epoch 17\\Batch 1800\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:44:12] Epoch 17\\Batch 2000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:46:07] Epoch 17\\Batch 2200\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:48:02] Epoch 17\\Batch 2400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:49:57] Epoch 17\\Batch 2600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:51:50] Epoch 17\\Batch 2800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:53:44] Epoch 17\\Batch 3000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:55:28] Epoch 17\\Batch 3200\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:57:23] Epoch 17\\Batch 3400\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 15:59:14] Epoch 17\\Batch 3600\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:01:10] Epoch 17\\Batch 3800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:02:59] Epoch 17\\Batch 4000\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:04:53] Epoch 17\\Batch 4200\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:06:50] Epoch 17\\Batch 4400\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:08:46] Epoch 17\\Batch 4600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:10:41] Epoch 17\\Batch 4800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:12:37] Epoch 17\\Batch 5000\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:14:32] Epoch 17\\Batch 5200\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:16:26] Epoch 17\\Batch 5400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:18:18] Epoch 17\\Batch 5600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/23 16:20:04] Epoch 17\\ Validation Loss:4.269/ Validation Accuracy:0.273\n",
      "[2019/03/23 16:22:02] Epoch 18\\Batch 200\\ Train Loss:4.162\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:23:54] Epoch 18\\Batch 400\\ Train Loss:4.160\\ Train Accuracy:0.292\n",
      "[2019/03/23 16:25:48] Epoch 18\\Batch 600\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:27:39] Epoch 18\\Batch 800\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:29:28] Epoch 18\\Batch 1000\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:31:23] Epoch 18\\Batch 1200\\ Train Loss:4.154\\ Train Accuracy:0.290\n",
      "[2019/03/23 16:33:20] Epoch 18\\Batch 1400\\ Train Loss:4.153\\ Train Accuracy:0.290\n",
      "[2019/03/23 16:35:15] Epoch 18\\Batch 1600\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:37:12] Epoch 18\\Batch 1800\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:39:08] Epoch 18\\Batch 2000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:41:01] Epoch 18\\Batch 2200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:42:55] Epoch 18\\Batch 2400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:44:44] Epoch 18\\Batch 2600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:46:36] Epoch 18\\Batch 2800\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:48:27] Epoch 18\\Batch 3000\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:50:18] Epoch 18\\Batch 3200\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:52:11] Epoch 18\\Batch 3400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:54:04] Epoch 18\\Batch 3600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:55:55] Epoch 18\\Batch 3800\\ Train Loss:4.152\\ Train Accuracy:0.291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/23 16:57:39] Epoch 18\\Batch 4000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 16:59:25] Epoch 18\\Batch 4200\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:01:13] Epoch 18\\Batch 4400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:03:01] Epoch 18\\Batch 4600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:04:47] Epoch 18\\Batch 4800\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:06:33] Epoch 18\\Batch 5000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:08:18] Epoch 18\\Batch 5200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:11:50] Epoch 18\\Batch 5600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/23 17:13:29] Epoch 18\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/23 17:15:14] Epoch 19\\Batch 200\\ Train Loss:4.161\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:17:03] Epoch 19\\Batch 400\\ Train Loss:4.159\\ Train Accuracy:0.292\n",
      "[2019/03/23 17:18:52] Epoch 19\\Batch 600\\ Train Loss:4.154\\ Train Accuracy:0.292\n",
      "[2019/03/23 17:20:39] Epoch 19\\Batch 800\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:22:26] Epoch 19\\Batch 1000\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:24:13] Epoch 19\\Batch 1200\\ Train Loss:4.153\\ Train Accuracy:0.290\n",
      "[2019/03/23 17:25:58] Epoch 19\\Batch 1400\\ Train Loss:4.153\\ Train Accuracy:0.290\n",
      "[2019/03/23 17:27:35] Epoch 19\\Batch 1600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:29:22] Epoch 19\\Batch 1800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:31:11] Epoch 19\\Batch 2000\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:32:58] Epoch 19\\Batch 2200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:34:45] Epoch 19\\Batch 2400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:36:32] Epoch 19\\Batch 2600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:38:20] Epoch 19\\Batch 2800\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:40:08] Epoch 19\\Batch 3000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:41:55] Epoch 19\\Batch 3200\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:43:42] Epoch 19\\Batch 3400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:45:27] Epoch 19\\Batch 3600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:47:13] Epoch 19\\Batch 3800\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:49:02] Epoch 19\\Batch 4000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:50:50] Epoch 19\\Batch 4200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:52:34] Epoch 19\\Batch 4400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:54:13] Epoch 19\\Batch 4600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:55:59] Epoch 19\\Batch 4800\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:57:49] Epoch 19\\Batch 5000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 17:59:38] Epoch 19\\Batch 5200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:01:30] Epoch 19\\Batch 5400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:03:24] Epoch 19\\Batch 5600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/23 18:05:09] Epoch 19\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/23 18:07:04] Epoch 20\\Batch 200\\ Train Loss:4.161\\ Train Accuracy:0.292\n",
      "[2019/03/23 18:08:57] Epoch 20\\Batch 400\\ Train Loss:4.159\\ Train Accuracy:0.292\n",
      "[2019/03/23 18:10:52] Epoch 20\\Batch 600\\ Train Loss:4.153\\ Train Accuracy:0.292\n",
      "[2019/03/23 18:12:46] Epoch 20\\Batch 800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:14:41] Epoch 20\\Batch 1000\\ Train Loss:4.154\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:16:34] Epoch 20\\Batch 1200\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:18:26] Epoch 20\\Batch 1400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:20:13] Epoch 20\\Batch 1600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:21:55] Epoch 20\\Batch 1800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:23:38] Epoch 20\\Batch 2000\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:25:31] Epoch 20\\Batch 2200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:27:26] Epoch 20\\Batch 2400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:29:18] Epoch 20\\Batch 2600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:31:11] Epoch 20\\Batch 2800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:33:04] Epoch 20\\Batch 3000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:34:55] Epoch 20\\Batch 3200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:36:47] Epoch 20\\Batch 3400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:38:41] Epoch 20\\Batch 3600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:40:34] Epoch 20\\Batch 3800\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:42:27] Epoch 20\\Batch 4000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:44:18] Epoch 20\\Batch 4200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:46:10] Epoch 20\\Batch 4400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:48:02] Epoch 20\\Batch 4600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:49:44] Epoch 20\\Batch 4800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:51:29] Epoch 20\\Batch 5000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:53:16] Epoch 20\\Batch 5200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:55:04] Epoch 20\\Batch 5400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 18:56:51] Epoch 20\\Batch 5600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/23 18:58:29] Epoch 20\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/23 19:00:17] Epoch 21\\Batch 200\\ Train Loss:4.161\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:02:05] Epoch 21\\Batch 400\\ Train Loss:4.158\\ Train Accuracy:0.292\n",
      "[2019/03/23 19:03:52] Epoch 21\\Batch 600\\ Train Loss:4.153\\ Train Accuracy:0.292\n",
      "[2019/03/23 19:05:39] Epoch 21\\Batch 800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:07:26] Epoch 21\\Batch 1000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:09:13] Epoch 21\\Batch 1200\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:11:01] Epoch 21\\Batch 1400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:12:48] Epoch 21\\Batch 1600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:14:36] Epoch 21\\Batch 1800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:16:23] Epoch 21\\Batch 2000\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:18:00] Epoch 21\\Batch 2200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:19:47] Epoch 21\\Batch 2400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:21:34] Epoch 21\\Batch 2600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:23:21] Epoch 21\\Batch 2800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:25:08] Epoch 21\\Batch 3000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:26:58] Epoch 21\\Batch 3200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:28:51] Epoch 21\\Batch 3400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:30:43] Epoch 21\\Batch 3600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:32:36] Epoch 21\\Batch 3800\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:34:26] Epoch 21\\Batch 4000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:36:15] Epoch 21\\Batch 4200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:38:05] Epoch 21\\Batch 4400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:39:55] Epoch 21\\Batch 4600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:41:42] Epoch 21\\Batch 4800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:43:30] Epoch 21\\Batch 5000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:45:05] Epoch 21\\Batch 5200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:46:53] Epoch 21\\Batch 5400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:48:45] Epoch 21\\Batch 5600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/23 19:50:27] Epoch 21\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/23 19:52:18] Epoch 22\\Batch 200\\ Train Loss:4.161\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:54:10] Epoch 22\\Batch 400\\ Train Loss:4.158\\ Train Accuracy:0.292\n",
      "[2019/03/23 19:56:01] Epoch 22\\Batch 600\\ Train Loss:4.153\\ Train Accuracy:0.292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/23 19:57:52] Epoch 22\\Batch 800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 19:59:44] Epoch 22\\Batch 1000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:01:36] Epoch 22\\Batch 1200\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:03:28] Epoch 22\\Batch 1400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:05:24] Epoch 22\\Batch 1600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:07:19] Epoch 22\\Batch 1800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:09:14] Epoch 22\\Batch 2000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:11:09] Epoch 22\\Batch 2200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:13:05] Epoch 22\\Batch 2400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:14:48] Epoch 22\\Batch 2600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:16:45] Epoch 22\\Batch 2800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:18:40] Epoch 22\\Batch 3000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:20:33] Epoch 22\\Batch 3200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:22:23] Epoch 22\\Batch 3400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:24:16] Epoch 22\\Batch 3600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:26:08] Epoch 22\\Batch 3800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:28:01] Epoch 22\\Batch 4000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:29:52] Epoch 22\\Batch 4200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:31:48] Epoch 22\\Batch 4400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:33:46] Epoch 22\\Batch 4600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:35:43] Epoch 22\\Batch 4800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:37:38] Epoch 22\\Batch 5000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:39:33] Epoch 22\\Batch 5200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:41:29] Epoch 22\\Batch 5400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:43:10] Epoch 22\\Batch 5600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/23 20:44:58] Epoch 22\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/23 20:46:53] Epoch 23\\Batch 200\\ Train Loss:4.161\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:48:46] Epoch 23\\Batch 400\\ Train Loss:4.158\\ Train Accuracy:0.292\n",
      "[2019/03/23 20:50:37] Epoch 23\\Batch 600\\ Train Loss:4.153\\ Train Accuracy:0.292\n",
      "[2019/03/23 20:52:33] Epoch 23\\Batch 800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:54:28] Epoch 23\\Batch 1000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:56:26] Epoch 23\\Batch 1200\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 20:58:20] Epoch 23\\Batch 1400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:00:15] Epoch 23\\Batch 1600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:02:11] Epoch 23\\Batch 1800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:04:06] Epoch 23\\Batch 2000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:06:02] Epoch 23\\Batch 2200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:07:57] Epoch 23\\Batch 2400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:09:49] Epoch 23\\Batch 2600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:11:41] Epoch 23\\Batch 2800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:13:19] Epoch 23\\Batch 3000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:15:15] Epoch 23\\Batch 3200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:17:07] Epoch 23\\Batch 3400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:18:57] Epoch 23\\Batch 3600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:20:49] Epoch 23\\Batch 3800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:22:42] Epoch 23\\Batch 4000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:24:34] Epoch 23\\Batch 4200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:26:26] Epoch 23\\Batch 4400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:28:17] Epoch 23\\Batch 4600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:30:06] Epoch 23\\Batch 4800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:31:59] Epoch 23\\Batch 5000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:33:52] Epoch 23\\Batch 5200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:35:44] Epoch 23\\Batch 5400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:37:36] Epoch 23\\Batch 5600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/23 21:39:17] Epoch 23\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/23 21:40:59] Epoch 24\\Batch 200\\ Train Loss:4.160\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:42:48] Epoch 24\\Batch 400\\ Train Loss:4.158\\ Train Accuracy:0.292\n",
      "[2019/03/23 21:44:37] Epoch 24\\Batch 600\\ Train Loss:4.153\\ Train Accuracy:0.292\n",
      "[2019/03/23 21:46:30] Epoch 24\\Batch 800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:48:22] Epoch 24\\Batch 1000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:50:14] Epoch 24\\Batch 1200\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:52:07] Epoch 24\\Batch 1400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:53:56] Epoch 24\\Batch 1600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:55:48] Epoch 24\\Batch 1800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:57:39] Epoch 24\\Batch 2000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 21:59:29] Epoch 24\\Batch 2200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:01:18] Epoch 24\\Batch 2400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:03:11] Epoch 24\\Batch 2600\\ Train Loss:4.149\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:05:03] Epoch 24\\Batch 2800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:06:56] Epoch 24\\Batch 3000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:08:45] Epoch 24\\Batch 3200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:10:26] Epoch 24\\Batch 3400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:12:19] Epoch 24\\Batch 3600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:14:10] Epoch 24\\Batch 3800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:16:04] Epoch 24\\Batch 4000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:17:54] Epoch 24\\Batch 4200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:19:47] Epoch 24\\Batch 4400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:21:39] Epoch 24\\Batch 4600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:23:34] Epoch 24\\Batch 4800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:25:27] Epoch 24\\Batch 5000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:27:19] Epoch 24\\Batch 5200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:29:12] Epoch 24\\Batch 5400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:31:03] Epoch 24\\Batch 5600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/23 22:32:47] Epoch 24\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/23 22:34:40] Epoch 25\\Batch 200\\ Train Loss:4.160\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:36:31] Epoch 25\\Batch 400\\ Train Loss:4.158\\ Train Accuracy:0.292\n",
      "[2019/03/23 22:38:13] Epoch 25\\Batch 600\\ Train Loss:4.153\\ Train Accuracy:0.292\n",
      "[2019/03/23 22:40:05] Epoch 25\\Batch 800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:41:56] Epoch 25\\Batch 1000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:43:43] Epoch 25\\Batch 1200\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:45:30] Epoch 25\\Batch 1400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:47:17] Epoch 25\\Batch 1600\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:49:04] Epoch 25\\Batch 1800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:50:50] Epoch 25\\Batch 2000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:52:37] Epoch 25\\Batch 2200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:54:23] Epoch 25\\Batch 2400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:56:11] Epoch 25\\Batch 2600\\ Train Loss:4.149\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:57:59] Epoch 25\\Batch 2800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 22:59:47] Epoch 25\\Batch 3000\\ Train Loss:4.151\\ Train Accuracy:0.291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/23 23:01:33] Epoch 25\\Batch 3200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:03:20] Epoch 25\\Batch 3400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:05:02] Epoch 25\\Batch 3600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:06:40] Epoch 25\\Batch 3800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:08:27] Epoch 25\\Batch 4000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:10:13] Epoch 25\\Batch 4200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:11:59] Epoch 25\\Batch 4400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:13:46] Epoch 25\\Batch 4600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:15:33] Epoch 25\\Batch 4800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:17:20] Epoch 25\\Batch 5000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:19:06] Epoch 25\\Batch 5200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:20:54] Epoch 25\\Batch 5400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:22:41] Epoch 25\\Batch 5600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/23 23:24:20] Epoch 25\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/23 23:26:07] Epoch 26\\Batch 200\\ Train Loss:4.160\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:27:53] Epoch 26\\Batch 400\\ Train Loss:4.158\\ Train Accuracy:0.292\n",
      "[2019/03/23 23:29:40] Epoch 26\\Batch 600\\ Train Loss:4.153\\ Train Accuracy:0.292\n",
      "[2019/03/23 23:31:25] Epoch 26\\Batch 800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:33:01] Epoch 26\\Batch 1000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:34:48] Epoch 26\\Batch 1200\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:36:34] Epoch 26\\Batch 1400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:38:22] Epoch 26\\Batch 1600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:40:09] Epoch 26\\Batch 1800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:41:55] Epoch 26\\Batch 2000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:43:43] Epoch 26\\Batch 2200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:45:30] Epoch 26\\Batch 2400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:47:16] Epoch 26\\Batch 2600\\ Train Loss:4.149\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:49:03] Epoch 26\\Batch 2800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:50:50] Epoch 26\\Batch 3000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:52:36] Epoch 26\\Batch 3200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:54:23] Epoch 26\\Batch 3400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:56:09] Epoch 26\\Batch 3600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:57:55] Epoch 26\\Batch 3800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/23 23:59:38] Epoch 26\\Batch 4000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:01:19] Epoch 26\\Batch 4200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:03:06] Epoch 26\\Batch 4400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:04:55] Epoch 26\\Batch 4600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:06:43] Epoch 26\\Batch 4800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:08:29] Epoch 26\\Batch 5000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:10:17] Epoch 26\\Batch 5200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:12:02] Epoch 26\\Batch 5400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:13:50] Epoch 26\\Batch 5600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/24 00:15:28] Epoch 26\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/24 00:17:16] Epoch 27\\Batch 200\\ Train Loss:4.160\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:19:02] Epoch 27\\Batch 400\\ Train Loss:4.158\\ Train Accuracy:0.292\n",
      "[2019/03/24 00:20:50] Epoch 27\\Batch 600\\ Train Loss:4.153\\ Train Accuracy:0.292\n",
      "[2019/03/24 00:22:37] Epoch 27\\Batch 800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:24:24] Epoch 27\\Batch 1000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:26:09] Epoch 27\\Batch 1200\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:27:49] Epoch 27\\Batch 1400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:29:35] Epoch 27\\Batch 1600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:31:22] Epoch 27\\Batch 1800\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:33:10] Epoch 27\\Batch 2000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:34:57] Epoch 27\\Batch 2200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:36:45] Epoch 27\\Batch 2400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:38:31] Epoch 27\\Batch 2600\\ Train Loss:4.149\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:40:20] Epoch 27\\Batch 2800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:42:06] Epoch 27\\Batch 3000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:43:54] Epoch 27\\Batch 3200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:45:41] Epoch 27\\Batch 3400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:47:29] Epoch 27\\Batch 3600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:49:15] Epoch 27\\Batch 3800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:51:02] Epoch 27\\Batch 4000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:52:50] Epoch 27\\Batch 4200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:54:29] Epoch 27\\Batch 4400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:56:12] Epoch 27\\Batch 4600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:57:58] Epoch 27\\Batch 4800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 00:59:47] Epoch 27\\Batch 5000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:01:33] Epoch 27\\Batch 5200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:03:20] Epoch 27\\Batch 5400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:05:07] Epoch 27\\Batch 5600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/24 01:06:47] Epoch 27\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/24 01:08:34] Epoch 28\\Batch 200\\ Train Loss:4.160\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:10:22] Epoch 28\\Batch 400\\ Train Loss:4.158\\ Train Accuracy:0.292\n",
      "[2019/03/24 01:12:08] Epoch 28\\Batch 600\\ Train Loss:4.153\\ Train Accuracy:0.292\n",
      "[2019/03/24 01:13:55] Epoch 28\\Batch 800\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:15:41] Epoch 28\\Batch 1000\\ Train Loss:4.153\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:17:28] Epoch 28\\Batch 1200\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:19:16] Epoch 28\\Batch 1400\\ Train Loss:4.152\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:20:57] Epoch 28\\Batch 1600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:22:39] Epoch 28\\Batch 1800\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:24:25] Epoch 28\\Batch 2000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:26:11] Epoch 28\\Batch 2200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:27:58] Epoch 28\\Batch 2400\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:29:44] Epoch 28\\Batch 2600\\ Train Loss:4.149\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:31:30] Epoch 28\\Batch 2800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:33:18] Epoch 28\\Batch 3000\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:35:04] Epoch 28\\Batch 3200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:36:50] Epoch 28\\Batch 3400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:38:37] Epoch 28\\Batch 3600\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:40:23] Epoch 28\\Batch 3800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:42:10] Epoch 28\\Batch 4000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:43:57] Epoch 28\\Batch 4200\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:45:43] Epoch 28\\Batch 4400\\ Train Loss:4.151\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:47:31] Epoch 28\\Batch 4600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:49:10] Epoch 28\\Batch 4800\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:50:51] Epoch 28\\Batch 5000\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:52:37] Epoch 28\\Batch 5200\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "[2019/03/24 01:54:23] Epoch 28\\Batch 5400\\ Train Loss:4.150\\ Train Accuracy:0.291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019/03/24 01:56:10] Epoch 28\\Batch 5600\\ Train Loss:4.150\\ Train Accuracy:0.291\n",
      "run model on validation data...\n",
      "[2019/03/24 01:57:47] Epoch 28\\ Validation Loss:4.268/ Validation Accuracy:0.273\n",
      "[2019/03/24 01:57:49] Validation Loss:4.268\\ Validation Accuracy:0.273\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache files exist, going to load in...\n",
      "loading h5_file...\n",
      "h5_file.keys: KeysView(<HDF5 file \"data.h5\" (mode r)>)\n",
      "loading pickle file\n",
      "cache files load successful!\n",
      "train_X.shape: (2959966, 200)\n",
      "train_y.shape: (2959966,)\n",
      "test_X.shape: (20000, 200)\n",
      "test_y.shape: (20000,)\n",
      "test_X[0]: [ 579  343 1173 1843    5  583  292 1173 1843    5 1180 1299  989   10\n",
      "    2   68  153  168  531  109  260  217  277   81   59   81  116  514\n",
      "    6  221  253  224  154  718  553    4  806  538  732  264   74    6\n",
      "  221  224  154  326   11  167  136    4  257  145   37   74  175  214\n",
      "   11   57  110  221    6  364   89   20 4050 2344    4  257   78    9\n",
      "  991  326  221   89  699  133   11  597  679 1957  824  884  871 1957\n",
      "  824    4  178   87   87   78  196   52  552   69   47   20   12   37\n",
      " 1371   89    6  755  779   81  667  597    4  586  878    6   35   93\n",
      "    7  719  285  937   35  162   13   11    7 1371   89   35    4  201\n",
      "   68   81   97 1533   81  667  597    9  991  326   35  343  704   16\n",
      "    5   99   13    9  991  654  583  292    4   13  221    6  795  230\n",
      "   11   11  350   12  495  235    7  990  625  718  553  297  215  954\n",
      "  549    4   12  165  198   67   93    9  166  110  146    4   81   86\n",
      "   93  141   87 1146  118  224  154   93  147    9   20    4   81  407\n",
      "   92  116  514   12]\n",
      "test_y[0]: 808\n",
      "[2019/03/24 08:30:16] restore from checkpoint\n",
      "INFO:tensorflow:Restoring parameters from testrnn_singlelabel_checkpoint_noembed/model.ckpt-28\n",
      "[2019/03/24 08:30:21] Validation Loss:4.218\\ Validation Accuracy:0.281\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
